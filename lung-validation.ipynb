{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e9d670c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "import albumentations as A\n",
    "\n",
    "from datasets.lungdatasets import SchenzenMontgomeryLungSegmentationDataset\n",
    "from datasets.lungdatasets import CheXpertLungSegmentationDataset\n",
    "from models.unet import ResNetUNet\n",
    "from utils.utils import bce_dice_loss, dice_metric\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import glob\n",
    "import cv2\n",
    "\n",
    "CHEXPERT_TRAIN = '../CheXpert-v1.0-small/train.csv'\n",
    "BASE_MASKS = './intermediate/out_lung_mask/'\n",
    "BASE_IMG = './data/chexpert-cardio-nofinding/'\n",
    "BASE_EXTRA = 'CheXpert-v1.0-small/train/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc2be060",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_transforms(size, test = True):\n",
    "    # Do test-time augmentation?\n",
    "    if test:\n",
    "        return A.Compose([\n",
    "        A.Resize(height=size, width=size, p=1.0)\n",
    "        ])\n",
    "    return A.Compose([\n",
    "        A.Resize(height=size, width=size, p=1.0),\n",
    "        A.HorizontalFlip(p=0.5),\n",
    "        A.RandomRotate90(p=0.3),\n",
    "        A.Transpose(p=0.3),\n",
    "        A.ShiftScaleRotate(shift_limit=0.05, scale_limit=0.2, rotate_limit=45, p=0.3),\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02bc2332",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Find Min skipping 0\n",
    "def find_min(arr):\n",
    "    min_val = 1000\n",
    "    for idx, value in enumerate(arr):\n",
    "        if value < min_val and value != 0:\n",
    "            min_val = value\n",
    "    return min_val\n",
    "\n",
    "def find_chest_width_image(img,post_process=True):\n",
    "    if post_process:\n",
    "        img = post_process_image(img)\n",
    "    start = np.argmax(img[:,:,1],axis=1)\n",
    "    end = np.argmax(img[:,::-1,1],axis=1)\n",
    "    h,w,c = img.shape\n",
    "    return find_min(start), w - find_min(end), w\n",
    "\n",
    "def find_chest_width(path,post_process=True):\n",
    "    img = cv2.imread(path)\n",
    "    if post_process:\n",
    "        img = post_process_image(img)\n",
    "    start = np.argmax(img[:,:,1],axis=1)\n",
    "    end = np.argmax(img[:,::-1,1],axis=1)\n",
    "    h,w,c = img.shape\n",
    "    return find_min(start), w - find_min(end), w\n",
    "\n",
    "def post_process_image(img,hull = True):\n",
    "    \n",
    "    dst = img[:,:,0]\n",
    "    \n",
    "    #kernel = np.ones((3, 3), np.uint8)\n",
    "    #dst = cv2.erode(dst, kernel,iterations= 3) \n",
    "\n",
    "    contours, hierarchy = cv2.findContours(dst, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "    #create an empty image for contours\n",
    "    img_contours = np.zeros(img.shape)\n",
    "    # draw the contours on the empty image\n",
    "    cs = [(c,cv2.contourArea(c)) for c in contours]\n",
    "    cs.sort(key=lambda x:x[1])\n",
    "    if hull:\n",
    "        hulls = [cv2.convexHull(p[0]) for p in cs[-2:]]\n",
    "        cv2.drawContours(img_contours, hulls, -1, (0,255,0), -1)\n",
    "    else:\n",
    "        contours2 = [p[0] for p in cs[-2:]]\n",
    "        cv2.drawContours(img_contours, contours2, -1, (0,255,0), -1)\n",
    "    return img_contours\n",
    "\n",
    "def find_img(path):\n",
    "    img = cv2.imread(path)\n",
    "    return img.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30d05ff2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "from matplotlib.pyplot import imshow\n",
    "\n",
    "ds_train_no_finding = CheXpertLungSegmentationDataset(\"./data/hand-label/nofinding.json\", '../CheXpert-v1.0-small/train/'\n",
    "                                                      , aug_transform=get_transforms(320)\n",
    "                                                     , test = True)\n",
    "ds_train_cardiomegaly = CheXpertLungSegmentationDataset(\"./data/hand-label/cardiomegaly-certain.json\", '../CheXpert-v1.0-small/train/'\n",
    "                                                        , aug_transform=get_transforms(320)\n",
    "                                                       , test = True)\n",
    "\n",
    "full_ds_chexpert = torch.utils.data.ConcatDataset([ds_train_no_finding, ds_train_cardiomegaly])\n",
    "\n",
    "print(len(ds_train_no_finding), len(ds_train_cardiomegaly), len(full_ds_chexpert))\n",
    "train_ds_chexpert,val_ds_chexpert = torch.utils.data.random_split(full_ds_chexpert, [len(full_ds_chexpert) - 100, 100], generator=torch.Generator().manual_seed(42))\n",
    "sample = np.uint8(full_ds_chexpert[0][1].cpu().numpy() * 255)\n",
    "\n",
    "ground_truth = {}\n",
    "for img,mask,path in val_ds_chexpert:\n",
    "    print(path)\n",
    "    mask = np.uint8(mask *255)\n",
    "    ground_truth[path] = find_chest_width_image((np.stack([mask,mask,mask])*255).transpose(1,2,0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f004a90d",
   "metadata": {},
   "outputs": [],
   "source": [
    "a, b = torch.utils.data.random_split(range(200), [100, 100], generator=torch.Generator().manual_seed(42))\n",
    "for i in a:\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b520dcca",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(10):\n",
    "    #print(full_ds_chexpert[i][2])\n",
    "    print(val_ds_chexpert[i][2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8375b86",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(val_ds_chexpert)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b973e347",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import torch\n",
    "from tqdm import tqdm\n",
    "import cv2\n",
    "import albumentations as A\n",
    "import numpy as np\n",
    "from datasets.lungdatasets import MEAN,STD\n",
    "from models.unet import ResNetUNet\n",
    "\n",
    "\n",
    "IMAGE_SIZE = 512\n",
    "\n",
    "LUNG_MODEL_WEIGHTS = './intermediate/lung_mask_weights'\n",
    "PATH = \"./intermediate/out_lung_mask3/\"\n",
    "\n",
    "#Remove last absolute path\n",
    "base_path = 'C:/Users/ignacio/workspace/stanford/cs230/CheXpert-v1.0-small/train/'\n",
    "CHEXPERT_VALIDATION_BASE = './data/chexpert-cardio-nofinding'\n",
    "\n",
    "paths = os.listdir(CHEXPERT_VALIDATION_BASE)\n",
    "inference_transforms = A.Compose([A.Resize(height=IMAGE_SIZE, width=IMAGE_SIZE, p=1.0)])\n",
    "\n",
    "def load_image(base_path, path):\n",
    "    path = path.replace('_','/',2)\n",
    "    img_path = base_path + path\n",
    "    image = cv2.imread(img_path,0)\n",
    "    image = cv2.merge([image,image,image])\n",
    "    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "    augmented = inference_transforms(image=image)\n",
    "    image = augmented['image']\n",
    "    image = A.Normalize(mean=MEAN, std=STD)(image=image)[\"image\"]\n",
    "    return torch.FloatTensor(image).unsqueeze(0)\n",
    "\n",
    "model = ResNetUNet().cuda()\n",
    "\n",
    "#best_weights = sorted(glob.glob(LUNG_MODEL_WEIGHTS + \"/*\"), key=lambda x: x[8:-5])[-1]\n",
    "\n",
    "checkpoint = torch.load('./intermediate/lung_mask_weights/pretraining0.903464_.pth')\n",
    "#checkpoint = torch.load('./intermediate/lung_mask_weights/afterpretraining0.941366_.pth')\n",
    "#checkpoint = torch.load('./intermediate/lung_mask_weights/nopretraining0.914747_.pth')\n",
    "model.load_state_dict(checkpoint['state_dict'])\n",
    "\n",
    "model.eval()\n",
    "predictions = {}\n",
    "\n",
    "for p in tqdm(paths): \n",
    "    if p in ground_truth:\n",
    "        img = load_image(base_path, p)\n",
    "        data_batch = img.permute(0, 3, 1, 2).cuda()\n",
    "        outputs = model(data_batch)\n",
    "\n",
    "        out_cut = np.copy(outputs.data.cpu().numpy())\n",
    "        out_cut[np.nonzero(out_cut < 0.5)] = 0.0\n",
    "        out_cut[np.nonzero(out_cut >= 0.5)] = 1.0\n",
    "\n",
    "        mask = ((out_cut[0].transpose(1, 2, 0) * 255).astype(np.uint8))[:,:,0]\n",
    "        prediction = find_chest_width_image((np.stack([mask,mask,mask]).transpose(1,2,0)))\n",
    "        predictions[p] = prediction\n",
    "        #cv2.imwrite(PATH + p, (out_cut[0].transpose(1, 2, 0) * 255).astype(np.uint8))\n",
    "    \n",
    "    #print(np.stack([mask,mask,mask]).shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d7e10fa",
   "metadata": {},
   "source": [
    "# Find errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75e649da",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(predictions))\n",
    "count = 0\n",
    "for p in predictions:\n",
    "    x0,x1,w = predictions[p]\n",
    "    \n",
    "    if (x1-x0)/w < 0.6:\n",
    "        count += 1\n",
    "        print(count, p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c91a15c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(ground_truth['patient00235_study1_view1_frontal.jpg'])\n",
    "#print(predictions['patient00235_study1_view1_frontal.jpg'])\n",
    "def compare(a,b):\n",
    "    x0,y0,w0 = a\n",
    "    x1,y1,w1 = b\n",
    "    \n",
    "    #print('Sarasa', x0/w0,y0/w0)\n",
    "    #print('Sarasa', x1/w1,y1/w1)\n",
    "    #print('dG', ((y0-x0)/w0))\n",
    "    #print('dP', ((y1-x1)/w1))\n",
    "    #print('Error',abs(((y1-x1)/w1) - ((y0-x0)/w0)))\n",
    "    return abs(((y1-x1)/w1) - ((y0-x0)/w0)), ((y0-x0)/w0), ((y1-x1)/w1)\n",
    "#compare(ground_truth['patient00235_study1_view1_frontal.jpg'],predictions['patient00235_study1_view1_frontal.jpg'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c0c2a89",
   "metadata": {},
   "outputs": [],
   "source": [
    "errors = []\n",
    "for k in ground_truth:\n",
    "    err,a,b = compare(ground_truth[k],predictions[k])\n",
    "    errors.append(err)\n",
    "errors = np.array(errors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90fd03dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(errors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "084aaa3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('RMSE:', np.sqrt((errors ** 2).sum()/len(errors)))\n",
    "print('Min:', errors.min())\n",
    "print('Max:', errors.max())\n",
    "print('Mean:', errors.mean())\n",
    "print('Median:', np.median(errors))\n",
    "print('STD:', errors.std())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cs230-project",
   "language": "python",
   "name": "cs230-project"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
