{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "9e9d670c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "import albumentations as A\n",
    "\n",
    "from datasets.lungdatasets import SchenzenMontgomeryLungSegmentationDataset\n",
    "from datasets.lungdatasets import CheXpertLungSegmentationDataset\n",
    "from models.unet import ResNetUNet\n",
    "from utils.utils import bce_dice_loss, dice_metric\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import glob\n",
    "import cv2\n",
    "\n",
    "CHEXPERT_TRAIN = '../CheXpert-v1.0-small/train.csv'\n",
    "BASE_MASKS = './intermediate/out_lung_mask/'\n",
    "BASE_IMG = './data/chexpert-cardio-nofinding/'\n",
    "BASE_EXTRA = 'CheXpert-v1.0-small/train/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "cc2be060",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_transforms(size, test = True):\n",
    "    #TODO: Do test-time augmentation?\n",
    "    if test:\n",
    "        return A.Compose([\n",
    "        A.Resize(height=size, width=size, p=1.0)\n",
    "        ])\n",
    "    return A.Compose([\n",
    "        A.Resize(height=size, width=size, p=1.0),\n",
    "        A.HorizontalFlip(p=0.5),\n",
    "        A.RandomRotate90(p=0.3),\n",
    "        A.Transpose(p=0.3),\n",
    "        A.ShiftScaleRotate(shift_limit=0.05, scale_limit=0.2, rotate_limit=45, p=0.3),\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "02bc2332",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Find Min skipping 0\n",
    "def find_min(arr):\n",
    "    min_val = 1000\n",
    "    for idx, value in enumerate(arr):\n",
    "        if value < min_val and value != 0:\n",
    "            min_val = value\n",
    "    return min_val\n",
    "\n",
    "def find_chest_width_image(img,post_process=True):\n",
    "    if post_process:\n",
    "        img = post_process_image(img)\n",
    "    start = np.argmax(img[:,:,1],axis=1)\n",
    "    end = np.argmax(img[:,::-1,1],axis=1)\n",
    "    h,w,c = img.shape\n",
    "    return find_min(start), w - find_min(end), w\n",
    "\n",
    "def find_chest_width(path,post_process=True):\n",
    "    img = cv2.imread(path)\n",
    "    if post_process:\n",
    "        img = post_process_image(img)\n",
    "    start = np.argmax(img[:,:,1],axis=1)\n",
    "    end = np.argmax(img[:,::-1,1],axis=1)\n",
    "    h,w,c = img.shape\n",
    "    return find_min(start), w - find_min(end), w\n",
    "\n",
    "def post_process_image(img,hull = True):\n",
    "    \n",
    "    dst = img[:,:,0]\n",
    "    \n",
    "    #kernel = np.ones((3, 3), np.uint8)\n",
    "    #dst = cv2.erode(dst, kernel,iterations= 3) \n",
    "\n",
    "    contours, hierarchy = cv2.findContours(dst, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "    #create an empty image for contours\n",
    "    img_contours = np.zeros(img.shape)\n",
    "    # draw the contours on the empty image\n",
    "    cs = [(c,cv2.contourArea(c)) for c in contours]\n",
    "    cs.sort(key=lambda x:x[1])\n",
    "    if hull:\n",
    "        hulls = [cv2.convexHull(p[0]) for p in cs[-2:]]\n",
    "        cv2.drawContours(img_contours, hulls, -1, (0,255,0), -1)\n",
    "    else:\n",
    "        contours2 = [p[0] for p in cs[-2:]]\n",
    "        cv2.drawContours(img_contours, contours2, -1, (0,255,0), -1)\n",
    "    return img_contours\n",
    "\n",
    "def find_img(path):\n",
    "    img = cv2.imread(path)\n",
    "    return img.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "30d05ff2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./data/hand-label/nofinding.json\n",
      "./data/hand-label/cardiomegaly-certain.json\n",
      "200 200 400\n",
      "patient33169_study1_view1_frontal.jpg\n",
      "patient10398_study3_view1_frontal.jpg\n",
      "patient14763_study1_view1_frontal.jpg\n",
      "patient26444_study1_view1_frontal.jpg\n",
      "patient16357_study1_view1_frontal.jpg\n",
      "patient06845_study3_view1_frontal.jpg\n",
      "patient21750_study1_view1_frontal.jpg\n",
      "patient31070_study2_view1_frontal.jpg\n",
      "patient02031_study1_view1_frontal.jpg\n",
      "patient15296_study6_view1_frontal.jpg\n",
      "patient30984_study2_view1_frontal.jpg\n",
      "patient26677_study1_view1_frontal.jpg\n",
      "patient34405_study1_view1_frontal.jpg\n",
      "patient18734_study1_view1_frontal.jpg\n",
      "patient13853_study5_view1_frontal.jpg\n",
      "patient30750_study1_view1_frontal.jpg\n",
      "patient04039_study1_view1_frontal.jpg\n",
      "patient10713_study5_view1_frontal.jpg\n",
      "patient30231_study4_view1_frontal.jpg\n",
      "patient07399_study1_view1_frontal.jpg\n",
      "patient14768_study1_view1_frontal.jpg\n",
      "patient25308_study1_view1_frontal.jpg\n",
      "patient31890_study12_view1_frontal.jpg\n",
      "patient22482_study3_view1_frontal.jpg\n",
      "patient02506_study2_view1_frontal.jpg\n",
      "patient20617_study3_view1_frontal.jpg\n",
      "patient08555_study1_view1_frontal.jpg\n",
      "patient22949_study1_view1_frontal.jpg\n",
      "patient00881_study1_view1_frontal.jpg\n",
      "patient00987_study2_view1_frontal.jpg\n",
      "patient32351_study1_view1_frontal.jpg\n",
      "patient20162_study5_view1_frontal.jpg\n",
      "patient32404_study1_view1_frontal.jpg\n",
      "patient12188_study1_view1_frontal.jpg\n",
      "patient09617_study3_view1_frontal.jpg\n",
      "patient12233_study1_view1_frontal.jpg\n",
      "patient26845_study1_view1_frontal.jpg\n",
      "patient23710_study5_view1_frontal.jpg\n",
      "patient15182_study1_view1_frontal.jpg\n",
      "patient22730_study6_view1_frontal.jpg\n",
      "patient15009_study11_view1_frontal.jpg\n",
      "patient33677_study1_view1_frontal.jpg\n",
      "patient15452_study2_view1_frontal.jpg\n",
      "patient26120_study3_view1_frontal.jpg\n",
      "patient26014_study1_view1_frontal.jpg\n",
      "patient29775_study1_view1_frontal.jpg\n",
      "patient08771_study1_view1_frontal.jpg\n",
      "patient20253_study8_view1_frontal.jpg\n",
      "patient21789_study3_view1_frontal.jpg\n",
      "patient04499_study1_view1_frontal.jpg\n",
      "patient23864_study2_view1_frontal.jpg\n",
      "patient24320_study2_view1_frontal.jpg\n",
      "patient31912_study1_view1_frontal.jpg\n",
      "patient30268_study1_view1_frontal.jpg\n",
      "patient27667_study1_view1_frontal.jpg\n",
      "patient25828_study4_view1_frontal.jpg\n",
      "patient10738_study3_view1_frontal.jpg\n",
      "patient23581_study2_view1_frontal.jpg\n",
      "patient13529_study1_view1_frontal.jpg\n",
      "patient29392_study4_view1_frontal.jpg\n",
      "patient16341_study1_view1_frontal.jpg\n",
      "patient01544_study1_view1_frontal.jpg\n",
      "patient15113_study3_view1_frontal.jpg\n",
      "patient09340_study3_view1_frontal.jpg\n",
      "patient04098_study4_view1_frontal.jpg\n",
      "patient02130_study1_view1_frontal.jpg\n",
      "patient04837_study1_view1_frontal.jpg\n",
      "patient20500_study2_view1_frontal.jpg\n",
      "patient12663_study3_view1_frontal.jpg\n",
      "patient33346_study5_view1_frontal.jpg\n",
      "patient23611_study1_view1_frontal.jpg\n",
      "patient03665_study3_view1_frontal.jpg\n",
      "patient09150_study2_view1_frontal.jpg\n",
      "patient22829_study3_view1_frontal.jpg\n",
      "patient16821_study1_view1_frontal.jpg\n",
      "patient04097_study1_view1_frontal.jpg\n",
      "patient00876_study1_view1_frontal.jpg\n",
      "patient10864_study9_view1_frontal.jpg\n",
      "patient12397_study1_view1_frontal.jpg\n",
      "patient32524_study1_view1_frontal.jpg\n",
      "patient11553_study1_view1_frontal.jpg\n",
      "patient14064_study1_view1_frontal.jpg\n",
      "patient21082_study5_view1_frontal.jpg\n",
      "patient11989_study2_view1_frontal.jpg\n",
      "patient03595_study1_view1_frontal.jpg\n",
      "patient01134_study1_view1_frontal.jpg\n",
      "patient14709_study1_view1_frontal.jpg\n",
      "patient29763_study12_view1_frontal.jpg\n",
      "patient10287_study1_view1_frontal.jpg\n",
      "patient19503_study1_view1_frontal.jpg\n",
      "patient21071_study2_view1_frontal.jpg\n",
      "patient10739_study1_view1_frontal.jpg\n",
      "patient14817_study1_view1_frontal.jpg\n",
      "patient32209_study3_view2_frontal.jpg\n",
      "patient13081_study1_view1_frontal.jpg\n",
      "patient01094_study11_view1_frontal.jpg\n",
      "patient31010_study3_view1_frontal.jpg\n",
      "patient01167_study48_view1_frontal.jpg\n",
      "patient31459_study1_view1_frontal.jpg\n",
      "patient21850_study1_view1_frontal.jpg\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "from matplotlib.pyplot import imshow\n",
    "\n",
    "ds_train_no_finding = CheXpertLungSegmentationDataset(\"./data/hand-label/nofinding.json\", '../CheXpert-v1.0-small/train/'\n",
    "                                                      , aug_transform=get_transforms(320)\n",
    "                                                     , test = True)\n",
    "ds_train_cardiomegaly = CheXpertLungSegmentationDataset(\"./data/hand-label/cardiomegaly-certain.json\", '../CheXpert-v1.0-small/train/'\n",
    "                                                        , aug_transform=get_transforms(320)\n",
    "                                                       , test = True)\n",
    "\n",
    "full_ds_chexpert = torch.utils.data.ConcatDataset([ds_train_no_finding, ds_train_cardiomegaly])\n",
    "\n",
    "print(len(ds_train_no_finding), len(ds_train_cardiomegaly), len(full_ds_chexpert))\n",
    "train_ds_chexpert,val_ds_chexpert = torch.utils.data.random_split(full_ds_chexpert, [len(full_ds_chexpert) - 100, 100], generator=torch.Generator().manual_seed(42))\n",
    "sample = np.uint8(full_ds_chexpert[0][1].cpu().numpy() * 255)\n",
    "\n",
    "ground_truth = {}\n",
    "for img,mask,path in val_ds_chexpert:\n",
    "    print(path)\n",
    "    mask = np.uint8(mask *255)\n",
    "    ground_truth[path] = find_chest_width_image((np.stack([mask,mask,mask])*255).transpose(1,2,0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "f004a90d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "142\n",
      "56\n",
      "198\n",
      "77\n",
      "50\n",
      "55\n",
      "4\n",
      "69\n",
      "174\n",
      "47\n",
      "88\n",
      "114\n",
      "58\n",
      "171\n",
      "155\n",
      "67\n",
      "195\n",
      "162\n",
      "111\n",
      "87\n",
      "7\n",
      "89\n",
      "121\n",
      "76\n",
      "115\n",
      "163\n",
      "61\n",
      "187\n",
      "199\n",
      "18\n",
      "152\n",
      "160\n",
      "123\n",
      "122\n",
      "53\n",
      "159\n",
      "127\n",
      "84\n",
      "8\n",
      "173\n",
      "66\n",
      "176\n",
      "14\n",
      "106\n",
      "71\n",
      "193\n",
      "95\n",
      "16\n",
      "133\n",
      "113\n",
      "170\n",
      "112\n",
      "12\n",
      "149\n",
      "41\n",
      "79\n",
      "183\n",
      "141\n",
      "136\n",
      "68\n",
      "86\n",
      "124\n",
      "70\n",
      "36\n",
      "78\n",
      "196\n",
      "73\n",
      "90\n",
      "1\n",
      "2\n",
      "117\n",
      "140\n",
      "80\n",
      "19\n",
      "144\n",
      "109\n",
      "99\n",
      "13\n",
      "128\n",
      "83\n",
      "134\n",
      "110\n",
      "37\n",
      "185\n",
      "60\n",
      "130\n",
      "23\n",
      "165\n",
      "42\n",
      "35\n",
      "157\n",
      "182\n",
      "49\n",
      "44\n",
      "28\n",
      "145\n",
      "92\n",
      "120\n",
      "48\n",
      "184\n"
     ]
    }
   ],
   "source": [
    "a, b = torch.utils.data.random_split(range(200), [100, 100], generator=torch.Generator().manual_seed(42))\n",
    "for i in a:\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "b520dcca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "patient33169_study1_view1_frontal.jpg\n",
      "patient10398_study3_view1_frontal.jpg\n",
      "patient14763_study1_view1_frontal.jpg\n",
      "patient26444_study1_view1_frontal.jpg\n",
      "patient16357_study1_view1_frontal.jpg\n",
      "patient06845_study3_view1_frontal.jpg\n",
      "patient21750_study1_view1_frontal.jpg\n",
      "patient31070_study2_view1_frontal.jpg\n",
      "patient02031_study1_view1_frontal.jpg\n",
      "patient15296_study6_view1_frontal.jpg\n"
     ]
    }
   ],
   "source": [
    "for i in range(10):\n",
    "    #print(full_ds_chexpert[i][2])\n",
    "    print(val_ds_chexpert[i][2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b8375b86",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(val_ds_chexpert)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "b973e347",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████| 9547/9547 [00:06<00:00, 1487.52it/s]\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import glob\n",
    "import torch\n",
    "from tqdm import tqdm\n",
    "import cv2\n",
    "import albumentations as A\n",
    "import numpy as np\n",
    "from datasets.lungdatasets import MEAN,STD\n",
    "from models.unet import ResNetUNet\n",
    "\n",
    "#TODO: Make out dir configurable with argparse\n",
    "IMAGE_SIZE = 512\n",
    "\n",
    "LUNG_MODEL_WEIGHTS = './intermediate/lung_mask_weights'\n",
    "PATH = \"./intermediate/out_lung_mask3/\"\n",
    "\n",
    "#TODO: Remove last absolute path\n",
    "base_path = 'C:/Users/ignacio/workspace/stanford/cs230/CheXpert-v1.0-small/train/'\n",
    "CHEXPERT_VALIDATION_BASE = './data/chexpert-cardio-nofinding'\n",
    "\n",
    "paths = os.listdir(CHEXPERT_VALIDATION_BASE)\n",
    "inference_transforms = A.Compose([A.Resize(height=IMAGE_SIZE, width=IMAGE_SIZE, p=1.0)])\n",
    "\n",
    "def load_image(base_path, path):\n",
    "    path = path.replace('_','/',2)\n",
    "    img_path = base_path + path\n",
    "    image = cv2.imread(img_path,0)\n",
    "    image = cv2.merge([image,image,image])\n",
    "    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "    augmented = inference_transforms(image=image)\n",
    "    image = augmented['image']\n",
    "    image = A.Normalize(mean=MEAN, std=STD)(image=image)[\"image\"]\n",
    "    return torch.FloatTensor(image).unsqueeze(0)\n",
    "\n",
    "model = ResNetUNet().cuda()\n",
    "\n",
    "#best_weights = sorted(glob.glob(LUNG_MODEL_WEIGHTS + \"/*\"), key=lambda x: x[8:-5])[-1]\n",
    "\n",
    "checkpoint = torch.load('./intermediate/lung_mask_weights/pretraining0.903464_.pth')\n",
    "#checkpoint = torch.load('./intermediate/lung_mask_weights/afterpretraining0.941366_.pth')\n",
    "#checkpoint = torch.load('./intermediate/lung_mask_weights/nopretraining0.914747_.pth')\n",
    "model.load_state_dict(checkpoint['state_dict'])\n",
    "\n",
    "model.eval()\n",
    "predictions = {}\n",
    "\n",
    "for p in tqdm(paths): \n",
    "    if p in ground_truth:\n",
    "        img = load_image(base_path, p)\n",
    "        data_batch = img.permute(0, 3, 1, 2).cuda()\n",
    "        outputs = model(data_batch)\n",
    "\n",
    "        out_cut = np.copy(outputs.data.cpu().numpy())\n",
    "        out_cut[np.nonzero(out_cut < 0.5)] = 0.0\n",
    "        out_cut[np.nonzero(out_cut >= 0.5)] = 1.0\n",
    "\n",
    "        mask = ((out_cut[0].transpose(1, 2, 0) * 255).astype(np.uint8))[:,:,0]\n",
    "        prediction = find_chest_width_image((np.stack([mask,mask,mask]).transpose(1,2,0)))\n",
    "        predictions[p] = prediction\n",
    "        #cv2.imwrite(PATH + p, (out_cut[0].transpose(1, 2, 0) * 255).astype(np.uint8))\n",
    "    \n",
    "    #print(np.stack([mask,mask,mask]).shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d7e10fa",
   "metadata": {},
   "source": [
    "# Find errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "75e649da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100\n"
     ]
    }
   ],
   "source": [
    "print(len(predictions))\n",
    "count = 0\n",
    "for p in predictions:\n",
    "    x0,x1,w = predictions[p]\n",
    "    \n",
    "    if (x1-x0)/w < 0.6:\n",
    "        count += 1\n",
    "        print(count, p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "2c91a15c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(ground_truth['patient00235_study1_view1_frontal.jpg'])\n",
    "#print(predictions['patient00235_study1_view1_frontal.jpg'])\n",
    "def compare(a,b):\n",
    "    x0,y0,w0 = a\n",
    "    x1,y1,w1 = b\n",
    "    \n",
    "    #print('Sarasa', x0/w0,y0/w0)\n",
    "    #print('Sarasa', x1/w1,y1/w1)\n",
    "    #print('dG', ((y0-x0)/w0))\n",
    "    #print('dP', ((y1-x1)/w1))\n",
    "    #print('Error',abs(((y1-x1)/w1) - ((y0-x0)/w0)))\n",
    "    return abs(((y1-x1)/w1) - ((y0-x0)/w0)), ((y0-x0)/w0), ((y1-x1)/w1)\n",
    "#compare(ground_truth['patient00235_study1_view1_frontal.jpg'],predictions['patient00235_study1_view1_frontal.jpg'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "1c0c2a89",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "patient29379_study1_view1_frontal.jpg 0.44921875 0.28125 0.73046875\n"
     ]
    }
   ],
   "source": [
    "errors = []\n",
    "for k in ground_truth:\n",
    "    err,a,b = compare(ground_truth[k],predictions[k])\n",
    "    if err > 0.3:\n",
    "        print(k,err,a,b)\n",
    "    else:\n",
    "        errors.append(err)\n",
    "errors = np.array(errors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "90fd03dc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "99"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(errors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "084aaa3b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 0.031283594434731866\n",
      "Min: 0.0003906249999999778\n",
      "Max: 0.18476562500000004\n",
      "Mean: 0.019511521464646464\n",
      "Median: 0.013671875\n",
      "STD: 0.024453298568729475\n"
     ]
    }
   ],
   "source": [
    "print('RMSE:', np.sqrt((errors ** 2).sum()/len(errors)))\n",
    "print('Min:', errors.min())\n",
    "print('Max:', errors.max())\n",
    "print('Mean:', errors.mean())\n",
    "print('Median:', np.median(errors))\n",
    "print('STD:', errors.std())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cs230-project",
   "language": "python",
   "name": "cs230-project"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
