{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "823ec915",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "with open(\"./data/hand-label/cardiomegaly-certain.json\", \"r\") as read_file:\n",
    "    data = json.load(read_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38d86307",
   "metadata": {},
   "outputs": [],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "422eacd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "data['images']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "596ab596",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CheXpertHeartDataset(Dataset):\n",
    "    def __init__(self, data_dir, image_dir, transforms=None):\n",
    "        super().__init__()\n",
    "\n",
    "        self.labels_paths = os.listdir(data_dir)\n",
    "        self.paths = [s.replace('_', '/', 2) for s in os.listdir(data_dir)]\n",
    "        self.paths = [s.replace('.txt', '.jpg') for s in self.paths]\n",
    "        self.data_dir = data_dir\n",
    "        self.image_dir = image_dir\n",
    "        self.transforms = transforms\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        image_path = self.paths[idx]\n",
    "        label_path = self.labels_paths[idx]\n",
    "        print(f'{self.image_dir}/{image_path}')\n",
    "        image = cv2.imread(f'{self.image_dir}/{image_path}', 0)\n",
    "        image = cv2.merge([image, image, image])\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB).astype(np.float32)\n",
    "        image /= 255.0\n",
    "        labels = pd.read_csv(self.data_dir + '/' + label_path, header=None, delimiter=\" \",\n",
    "                             names=['clazz', 'x_min', 'y_min', 'x_max', 'y_max'])\n",
    "\n",
    "        labels = labels[labels.clazz.eq(0)]\n",
    "\n",
    "        height, width, _ = image.shape\n",
    "        x, y, w, h = labels[['x_min', 'y_min', 'x_max', 'y_max']].values[0]\n",
    "\n",
    "        boxes = torch.as_tensor(\n",
    "            np.array([[(x - (w / 2)) * width, (y - (h / 2)) * height, (x + (w / 2)) * width, (y + (h / 2)) * height]]),\n",
    "            dtype=torch.float32)\n",
    "        area = (boxes[:, 3] - boxes[:, 1]) * (boxes[:, 2] - boxes[:, 0])\n",
    "        area = torch.as_tensor(area, dtype=torch.float32)\n",
    "        labels = torch.squeeze(torch.as_tensor((labels.clazz.values,), dtype=torch.int64)) + 1\n",
    "\n",
    "        # suppose all instances are not crowd\n",
    "        iscrowd = torch.zeros((1,), dtype=torch.int64)\n",
    "        target = {}\n",
    "        target['boxes'] = boxes\n",
    "        target['labels'] = labels\n",
    "        # target['masks'] = None\n",
    "        target['image_id'] = torch.tensor([idx])\n",
    "        target['area'] = area\n",
    "        target['iscrowd'] = iscrowd\n",
    "\n",
    "        if self.transforms is not None:\n",
    "            image = self.transforms(image)\n",
    "\n",
    "        return image, target\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.paths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "225fba81",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78a11103",
   "metadata": {},
   "outputs": [],
   "source": [
    "data['images'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e990b72",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23711ebc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.utils import annotation2binarymask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35eb0129",
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca08257a",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_data, annotation = data['images'][idx], data['annotations'][idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10ece603",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "from matplotlib.pyplot import imshow\n",
    "\n",
    "for idx, d in enumerate(data['images'][179:180]):\n",
    "    w,h = d['width'], d['height']\n",
    "    print(idx, d['file_name'])\n",
    "    annotations = [x for x in data['annotations'] if x['image_id'] == d['id']]\n",
    "    mask = annotation2binarymask(annotations,h,w)\n",
    "    print(mask.shape)\n",
    "    imshow(mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cd4c71f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from datasets.lungdatasets import MEAN,STD\n",
    "import albumentations as A\n",
    "import torch\n",
    "\n",
    "def get_transforms(size, test = False):\n",
    "    #TODO: Do test-time augmentation?\n",
    "    return A.Compose([\n",
    "        A.Resize(height=size, width=size, p=1.0),\n",
    "        A.HorizontalFlip(p=0.5),\n",
    "        A.RandomRotate90(p=0.3),\n",
    "        A.Transpose(p=0.3),\n",
    "        A.ShiftScaleRotate(shift_limit=0.05, scale_limit=0.2, rotate_limit=45, p=0.3),\n",
    "    ])\n",
    "\n",
    "\n",
    "class CheXpertLungSegmentationDataset(Dataset):\n",
    "    def __init__(self, data_dir, image_dir, aug_transform, mean=MEAN,std=STD):\n",
    "        with open(data_dir, \"r\") as read_file:\n",
    "            self.data = json.load(read_file)\n",
    "    \n",
    "        self.image_dir = image_dir\n",
    "        self.data_dir = data_dir\n",
    "        self.aug_transform = aug_transform\n",
    "        self.norm_transform = A.Normalize(mean=mean, std=std)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        whole_data = self.data['images']\n",
    "        d = whole_data[idx]\n",
    "        w,h = d['width'], d['height']\n",
    "        annotations = [x for x in data['annotations'] if x['image_id'] == d['id']]\n",
    "        mask = annotation2binarymask(annotations,h,w)\n",
    "        print(mask.shape)\n",
    "        print(d['file_name'])\n",
    "        img_path = self.image_dir + d['file_name'].replace('_','/', 2)\n",
    "        print(img_path)\n",
    "        img = cv2.imread(img_path)\n",
    "        print(img.shape)\n",
    "        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "        \n",
    "        augmented = self.aug_transform(image=img, mask=mask)\n",
    "        img = augmented['image']\n",
    "        mask = augmented['mask']\n",
    "        img = self.norm_transform(image=img)[\"image\"]\n",
    "        return torch.FloatTensor(img), torch.FloatTensor(mask)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data['images'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6e34d81",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = CheXpertLungSegmentationDataset(\"./data/hand-label/cardiomegaly-certain.json\", '../CheXpert-v1.0-small/train/', aug_transform=get_transforms(320))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfd7268c",
   "metadata": {},
   "outputs": [],
   "source": [
    "imshow((ds[0][0] + MEAN)*STD)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ec2f0fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "imshow(ds[0][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1443bb43",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95c97052",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SchenzenMontgomeryLungSegmentationDataset(Dataset):\n",
    "    def __init__(self, df, data_dir, aug_transform, test=False, mean=MEAN,std=STD):\n",
    "        self.df = df\n",
    "        self.data_dir = data_dir\n",
    "        self.test = test\n",
    "        self.aug_transform = aug_transform\n",
    "        self.norm_transform = A.Normalize(mean=mean, std=std)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        if self.test:\n",
    "            img_path = self.data_dir + 'data/test/' + self.df.iloc[idx, 0] + \".png\"\n",
    "        else:\n",
    "            img_path = self.data_dir + 'data/CXR_png/' + self.df.iloc[idx, 0] + \".png\"\n",
    "\n",
    "        img = cv2.imread(img_path)\n",
    "        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "        if self.test:\n",
    "            augmented = self.aug_transform(image=img)\n",
    "            img = augmented['image']\n",
    "            img = self.norm_transform(image=img)[\"image\"]\n",
    "            return torch.FloatTensor(img)\n",
    "        else:\n",
    "            ending = '_mask.png' if self.df.iloc[idx, 0].startswith('CHN') else '.png'\n",
    "            mask_path = self.data_dir + 'data/masks/' + self.df.iloc[idx, 0] + ending\n",
    "            mask = cv2.imread(mask_path)[:, :, 0]\n",
    "            mask = np.clip(mask, 0, 1).astype(\"float32\")\n",
    "\n",
    "            augmented = self.aug_transform(image=img, mask=mask)\n",
    "            img = augmented['image']\n",
    "            mask = augmented['mask']\n",
    "            img = self.norm_transform(image=img)[\"image\"]\n",
    "            return torch.FloatTensor(img), torch.FloatTensor(mask)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cs230-project",
   "language": "python",
   "name": "cs230-project"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
