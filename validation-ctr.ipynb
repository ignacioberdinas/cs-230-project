{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b3fe7ebd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_iou(a, b, epsilon=1e-5):\n",
    "    \"\"\" Given two boxes `a` and `b` defined as a list of four numbers:\n",
    "            [x1,y1,x2,y2]\n",
    "        where:\n",
    "            x1,y1 represent the upper left corner\n",
    "            x2,y2 represent the lower right corner\n",
    "        It returns the Intersect of Union score for these two boxes.\n",
    "\n",
    "    Args:\n",
    "        a:          (list of 4 numbers) [x1,y1,x2,y2]\n",
    "        b:          (list of 4 numbers) [x1,y1,x2,y2]\n",
    "        epsilon:    (float) Small value to prevent division by zero\n",
    "\n",
    "    Returns:\n",
    "        (float) The Intersect of Union score.\n",
    "    \"\"\"\n",
    "    # COORDINATES OF THE INTERSECTION BOX\n",
    "    x1 = max(a[0], b[0])\n",
    "    y1 = max(a[1], b[1])\n",
    "    x2 = min(a[2], b[2])\n",
    "    y2 = min(a[3], b[3])\n",
    "\n",
    "    # AREA OF OVERLAP - Area where the boxes intersect\n",
    "    width = (x2 - x1)\n",
    "    height = (y2 - y1)\n",
    "    # handle case where there is NO overlap\n",
    "    if (width<0) or (height <0):\n",
    "        return 0.0\n",
    "    area_overlap = width * height\n",
    "\n",
    "    # COMBINED AREA\n",
    "    area_a = (a[2] - a[0]) * (a[3] - a[1])\n",
    "    area_b = (b[2] - b[0]) * (b[3] - b[1])\n",
    "    area_combined = area_a + area_b - area_overlap\n",
    "\n",
    "    # RATIO OF AREA OF OVERLAP OVER COMBINED AREA\n",
    "    iou = area_overlap / (area_combined+epsilon)\n",
    "    return iou"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e92ad7bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./data/hand-label/nofinding.json\n",
      "./data/hand-label/cardiomegaly-certain.json\n",
      "patient33169_study1_view1_frontal.jpg\n",
      "patient10398_study3_view1_frontal.jpg\n",
      "patient14763_study1_view1_frontal.jpg\n",
      "patient26444_study1_view1_frontal.jpg\n",
      "patient16357_study1_view1_frontal.jpg\n",
      "patient06845_study3_view1_frontal.jpg\n",
      "patient21750_study1_view1_frontal.jpg\n",
      "patient31070_study2_view1_frontal.jpg\n",
      "patient02031_study1_view1_frontal.jpg\n",
      "patient15296_study6_view1_frontal.jpg\n",
      "patient30984_study2_view1_frontal.jpg\n",
      "patient26677_study1_view1_frontal.jpg\n",
      "patient34405_study1_view1_frontal.jpg\n",
      "patient18734_study1_view1_frontal.jpg\n",
      "patient13853_study5_view1_frontal.jpg\n",
      "patient30750_study1_view1_frontal.jpg\n",
      "patient04039_study1_view1_frontal.jpg\n",
      "patient10713_study5_view1_frontal.jpg\n",
      "patient30231_study4_view1_frontal.jpg\n",
      "patient07399_study1_view1_frontal.jpg\n",
      "patient14768_study1_view1_frontal.jpg\n",
      "patient25308_study1_view1_frontal.jpg\n",
      "patient31890_study12_view1_frontal.jpg\n",
      "patient22482_study3_view1_frontal.jpg\n",
      "patient02506_study2_view1_frontal.jpg\n",
      "patient20617_study3_view1_frontal.jpg\n",
      "patient08555_study1_view1_frontal.jpg\n",
      "patient22949_study1_view1_frontal.jpg\n",
      "patient00881_study1_view1_frontal.jpg\n",
      "patient00987_study2_view1_frontal.jpg\n",
      "patient32351_study1_view1_frontal.jpg\n",
      "patient20162_study5_view1_frontal.jpg\n",
      "patient32404_study1_view1_frontal.jpg\n",
      "patient12188_study1_view1_frontal.jpg\n",
      "patient09617_study3_view1_frontal.jpg\n",
      "patient12233_study1_view1_frontal.jpg\n",
      "patient26845_study1_view1_frontal.jpg\n",
      "patient23710_study5_view1_frontal.jpg\n",
      "patient15182_study1_view1_frontal.jpg\n",
      "patient22730_study6_view1_frontal.jpg\n",
      "patient15009_study11_view1_frontal.jpg\n",
      "patient33677_study1_view1_frontal.jpg\n",
      "patient15452_study2_view1_frontal.jpg\n",
      "patient26120_study3_view1_frontal.jpg\n",
      "patient26014_study1_view1_frontal.jpg\n",
      "patient29775_study1_view1_frontal.jpg\n",
      "patient08771_study1_view1_frontal.jpg\n",
      "patient20253_study8_view1_frontal.jpg\n",
      "patient21789_study3_view1_frontal.jpg\n",
      "patient04499_study1_view1_frontal.jpg\n",
      "patient23864_study2_view1_frontal.jpg\n",
      "patient24320_study2_view1_frontal.jpg\n",
      "patient31912_study1_view1_frontal.jpg\n",
      "patient30268_study1_view1_frontal.jpg\n",
      "patient27667_study1_view1_frontal.jpg\n",
      "patient25828_study4_view1_frontal.jpg\n",
      "patient10738_study3_view1_frontal.jpg\n",
      "patient23581_study2_view1_frontal.jpg\n",
      "patient13529_study1_view1_frontal.jpg\n",
      "patient29392_study4_view1_frontal.jpg\n",
      "patient16341_study1_view1_frontal.jpg\n",
      "patient01544_study1_view1_frontal.jpg\n",
      "patient15113_study3_view1_frontal.jpg\n",
      "patient09340_study3_view1_frontal.jpg\n",
      "patient04098_study4_view1_frontal.jpg\n",
      "patient02130_study1_view1_frontal.jpg\n",
      "patient04837_study1_view1_frontal.jpg\n",
      "patient20500_study2_view1_frontal.jpg\n",
      "patient12663_study3_view1_frontal.jpg\n",
      "patient33346_study5_view1_frontal.jpg\n",
      "patient23611_study1_view1_frontal.jpg\n",
      "patient03665_study3_view1_frontal.jpg\n",
      "patient09150_study2_view1_frontal.jpg\n",
      "patient22829_study3_view1_frontal.jpg\n",
      "patient16821_study1_view1_frontal.jpg\n",
      "patient04097_study1_view1_frontal.jpg\n",
      "patient00876_study1_view1_frontal.jpg\n",
      "patient10864_study9_view1_frontal.jpg\n",
      "patient12397_study1_view1_frontal.jpg\n",
      "patient32524_study1_view1_frontal.jpg\n",
      "patient11553_study1_view1_frontal.jpg\n",
      "patient14064_study1_view1_frontal.jpg\n",
      "patient21082_study5_view1_frontal.jpg\n",
      "patient11989_study2_view1_frontal.jpg\n",
      "patient03595_study1_view1_frontal.jpg\n",
      "patient01134_study1_view1_frontal.jpg\n",
      "patient14709_study1_view1_frontal.jpg\n",
      "patient29763_study12_view1_frontal.jpg\n",
      "patient10287_study1_view1_frontal.jpg\n",
      "patient19503_study1_view1_frontal.jpg\n",
      "patient21071_study2_view1_frontal.jpg\n",
      "patient10739_study1_view1_frontal.jpg\n",
      "patient14817_study1_view1_frontal.jpg\n",
      "patient32209_study3_view2_frontal.jpg\n",
      "patient13081_study1_view1_frontal.jpg\n",
      "patient01094_study11_view1_frontal.jpg\n",
      "patient31010_study3_view1_frontal.jpg\n",
      "patient01167_study48_view1_frontal.jpg\n",
      "patient31459_study1_view1_frontal.jpg\n",
      "patient21850_study1_view1_frontal.jpg\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "import albumentations as A\n",
    "\n",
    "from datasets.lungdatasets import SchenzenMontgomeryLungSegmentationDataset\n",
    "from datasets.lungdatasets import CheXpertLungSegmentationDataset\n",
    "from models.unet import ResNetUNet\n",
    "from utils.utils import bce_dice_loss, dice_metric\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import glob\n",
    "import cv2\n",
    "\n",
    "CHEXPERT_TRAIN = '../CheXpert-v1.0-small/train.csv'\n",
    "BASE_MASKS = './intermediate/out_lung_mask/'\n",
    "BASE_IMG = './data/chexpert-cardio-nofinding/'\n",
    "BASE_EXTRA = 'CheXpert-v1.0-small/train/'\n",
    "\n",
    "def get_transforms(size, test = True):\n",
    "    #TODO: Do test-time augmentation?\n",
    "    if test:\n",
    "        return A.Compose([\n",
    "        A.Resize(height=size, width=size, p=1.0)\n",
    "        ])\n",
    "    return A.Compose([\n",
    "        A.Resize(height=size, width=size, p=1.0),\n",
    "        A.HorizontalFlip(p=0.5),\n",
    "        A.RandomRotate90(p=0.3),\n",
    "        A.Transpose(p=0.3),\n",
    "        A.ShiftScaleRotate(shift_limit=0.05, scale_limit=0.2, rotate_limit=45, p=0.3),\n",
    "    ])\n",
    "\n",
    "#Find Min skipping 0\n",
    "def find_min(arr):\n",
    "    min_val = 1000\n",
    "    for idx, value in enumerate(arr):\n",
    "        if value < min_val and value != 0:\n",
    "            min_val = value\n",
    "    return min_val\n",
    "\n",
    "def find_chest_width_image(img,post_process=True):\n",
    "    if post_process:\n",
    "        img = post_process_image(img)\n",
    "    start = np.argmax(img[:,:,1],axis=1)\n",
    "    end = np.argmax(img[:,::-1,1],axis=1)\n",
    "    h,w,c = img.shape\n",
    "    return find_min(start), w - find_min(end), w\n",
    "\n",
    "def find_chest_width(path,post_process=True):\n",
    "    img = cv2.imread(path)\n",
    "    if post_process:\n",
    "        img = post_process_image(img)\n",
    "    start = np.argmax(img[:,:,1],axis=1)\n",
    "    end = np.argmax(img[:,::-1,1],axis=1)\n",
    "    h,w,c = img.shape\n",
    "    return find_min(start), w - find_min(end), w\n",
    "\n",
    "def post_process_image(img,hull = True):\n",
    "    \n",
    "    dst = img[:,:,0]\n",
    "    \n",
    "    #kernel = np.ones((3, 3), np.uint8)\n",
    "    #dst = cv2.erode(dst, kernel,iterations= 3) \n",
    "\n",
    "    contours, hierarchy = cv2.findContours(dst, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "    #create an empty image for contours\n",
    "    img_contours = np.zeros(img.shape)\n",
    "    # draw the contours on the empty image\n",
    "    cs = [(c,cv2.contourArea(c)) for c in contours]\n",
    "    cs.sort(key=lambda x:x[1])\n",
    "    if hull:\n",
    "        hulls = [cv2.convexHull(p[0]) for p in cs[-2:]]\n",
    "        cv2.drawContours(img_contours, hulls, -1, (0,255,0), -1)\n",
    "    else:\n",
    "        contours2 = [p[0] for p in cs[-2:]]\n",
    "        cv2.drawContours(img_contours, contours2, -1, (0,255,0), -1)\n",
    "    return img_contours\n",
    "\n",
    "def find_img(path):\n",
    "    img = cv2.imread(path)\n",
    "    return img.shape\n",
    "\n",
    "import numpy as np\n",
    "import cv2\n",
    "from matplotlib.pyplot import imshow\n",
    "\n",
    "ds_train_no_finding = CheXpertLungSegmentationDataset(\"./data/hand-label/nofinding.json\", '../CheXpert-v1.0-small/train/'\n",
    "                                                      , aug_transform=get_transforms(320)\n",
    "                                                     , test = True)\n",
    "ds_train_cardiomegaly = CheXpertLungSegmentationDataset(\"./data/hand-label/cardiomegaly-certain.json\", '../CheXpert-v1.0-small/train/'\n",
    "                                                        , aug_transform=get_transforms(320)\n",
    "                                                       , test = True)\n",
    "\n",
    "full_ds_chexpert1 = torch.utils.data.ConcatDataset([ds_train_no_finding, ds_train_cardiomegaly])\n",
    "train_ds_chexpert1,val_ds_chexpert1 = torch.utils.data.random_split(full_ds_chexpert1, [len(full_ds_chexpert1) - 100, 100], generator=torch.Generator().manual_seed(42))\n",
    "sample = np.uint8(full_ds_chexpert1[0][1].cpu().numpy() * 255)\n",
    "\n",
    "ground_truth_lungs = {}\n",
    "for img,mask,path in val_ds_chexpert1:\n",
    "    print(path)\n",
    "    mask = np.uint8(mask *255)\n",
    "    ground_truth_lungs[path] = find_chest_width_image((np.stack([mask,mask,mask])*255).transpose(1,2,0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "95be3fc9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████| 9547/9547 [00:12<00:00, 751.81it/s]\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import glob\n",
    "import torch\n",
    "from tqdm import tqdm\n",
    "import cv2\n",
    "import albumentations as A\n",
    "import numpy as np\n",
    "from datasets.lungdatasets import MEAN,STD\n",
    "from models.unet import ResNetUNet\n",
    "\n",
    "#TODO: Make out dir configurable with argparse\n",
    "IMAGE_SIZE = 512\n",
    "\n",
    "LUNG_MODEL_WEIGHTS = './intermediate/lung_mask_weights'\n",
    "PATH = \"./intermediate/out_lung_mask3/\"\n",
    "\n",
    "#TODO: Remove last absolute path\n",
    "base_path = 'C:/Users/ignacio/workspace/stanford/cs230/CheXpert-v1.0-small/train/'\n",
    "CHEXPERT_VALIDATION_BASE = './data/chexpert-cardio-nofinding'\n",
    "\n",
    "paths = os.listdir(CHEXPERT_VALIDATION_BASE)\n",
    "inference_transforms = A.Compose([A.Resize(height=IMAGE_SIZE, width=IMAGE_SIZE, p=1.0)])\n",
    "\n",
    "def load_image(base_path, path):\n",
    "    path = path.replace('_','/',2)\n",
    "    img_path = base_path + path\n",
    "    image = cv2.imread(img_path,0)\n",
    "    image = cv2.merge([image,image,image])\n",
    "    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "    augmented = inference_transforms(image=image)\n",
    "    image = augmented['image']\n",
    "    image = A.Normalize(mean=MEAN, std=STD)(image=image)[\"image\"]\n",
    "    return torch.FloatTensor(image).unsqueeze(0)\n",
    "\n",
    "model = ResNetUNet().cuda()\n",
    "\n",
    "#best_weights = sorted(glob.glob(LUNG_MODEL_WEIGHTS + \"/*\"), key=lambda x: x[8:-5])[-1]\n",
    "\n",
    "#checkpoint = torch.load('./intermediate/lung_mask_weights/pretraining0.903464_.pth')\n",
    "checkpoint = torch.load('./intermediate/lung_mask_weights/afterpretraining0.941366_.pth')\n",
    "#checkpoint = torch.load('./intermediate/lung_mask_weights/nopretraining0.914747_.pth')\n",
    "model.load_state_dict(checkpoint['state_dict'])\n",
    "\n",
    "model.eval()\n",
    "predictions_lungs = {}\n",
    "\n",
    "for p in tqdm(paths): \n",
    "    if p in ground_truth_lungs:\n",
    "        img = load_image(base_path, p)\n",
    "        data_batch = img.permute(0, 3, 1, 2).cuda()\n",
    "        outputs = model(data_batch)\n",
    "\n",
    "        out_cut = np.copy(outputs.data.cpu().numpy())\n",
    "        out_cut[np.nonzero(out_cut < 0.5)] = 0.0\n",
    "        out_cut[np.nonzero(out_cut >= 0.5)] = 1.0\n",
    "\n",
    "        mask = ((out_cut[0].transpose(1, 2, 0) * 255).astype(np.uint8))[:,:,0]\n",
    "        prediction = find_chest_width_image((np.stack([mask,mask,mask]).transpose(1,2,0)))\n",
    "        predictions_lungs[p] = prediction\n",
    "        #cv2.imwrite(PATH + p, (out_cut[0].transpose(1, 2, 0) * 255).astype(np.uint8))\n",
    "    \n",
    "    #print(np.stack([mask,mask,mask]).shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21fb8d35",
   "metadata": {},
   "source": [
    "# Heart"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "565ff4d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100\n",
      "{'boxes': tensor([[140.1379, 179.6414, 220.4688, 218.4827]]), 'labels': tensor([1]), 'image_id': tensor([196]), 'extra': 'patient33169/study1/view1_frontal.jpg', 'area': tensor([3120.1550]), 'iscrowd': tensor([0])}\n",
      "{'boxes': tensor([[158.4586, 169.4896, 270.1276, 229.9587]]), 'labels': tensor([1]), 'image_id': tensor([51]), 'extra': 'patient10398/study3/view1_frontal.jpg', 'area': tensor([6752.5278]), 'iscrowd': tensor([0])}\n",
      "{'boxes': tensor([[141.4621, 204.8000, 250.4829, 249.3792]]), 'labels': tensor([1]), 'image_id': tensor([82]), 'extra': 'patient14763/study1/view1_frontal.jpg', 'area': tensor([4860.0591]), 'iscrowd': tensor([0])}\n",
      "{'boxes': tensor([[136.6070, 203.9171, 245.1862, 251.1446]]), 'labels': tensor([1]), 'image_id': tensor([149]), 'extra': 'patient26444/study1/view1_frontal.jpg', 'area': tensor([5127.9263]), 'iscrowd': tensor([0])}\n",
      "{'boxes': tensor([[115.6171, 190.2344, 298.3481, 289.5448]]), 'labels': tensor([1]), 'image_id': tensor([99]), 'extra': 'patient16357/study1/view1_frontal.jpg', 'area': tensor([18147.0840]), 'iscrowd': tensor([0])}\n",
      "{'boxes': tensor([[161.1071, 170.3725, 276.7484, 249.8208]]), 'labels': tensor([1]), 'image_id': tensor([29]), 'extra': 'patient06845/study3/view1_frontal.jpg', 'area': tensor([9187.5068]), 'iscrowd': tensor([0])}\n",
      "{'boxes': tensor([[103.0619, 152.2760, 229.2965, 239.6690]]), 'labels': tensor([1]), 'image_id': tensor([131]), 'extra': 'patient21750/study1/view1_frontal.jpg', 'area': tensor([11032.0117]), 'iscrowd': tensor([0])}\n",
      "{'boxes': tensor([[126.4550, 197.7379, 218.7034, 241.4346]]), 'labels': tensor([1]), 'image_id': tensor([180]), 'extra': 'patient31070/study2/view1_frontal.jpg', 'area': tensor([4030.9414]), 'iscrowd': tensor([0])}\n",
      "{'boxes': tensor([[139.3517, 179.6419, 253.9297, 258.2096]]), 'labels': tensor([1]), 'image_id': tensor([6]), 'extra': 'patient02031/study1/view1_frontal.jpg', 'area': tensor([9002.1309]), 'iscrowd': tensor([0])}\n",
      "{'boxes': tensor([[113.0675, 135.9270, 258.2925, 217.3945]]), 'labels': tensor([1]), 'image_id': tensor([87]), 'extra': 'patient15296/study6/view1_frontal.jpg', 'area': tensor([11831.1211]), 'iscrowd': tensor([0])}\n",
      "{'boxes': tensor([[111.4482, 222.8965, 216.9378, 260.8552]]), 'labels': tensor([1]), 'image_id': tensor([178]), 'extra': 'patient30984/study2/view1_frontal.jpg', 'area': tensor([4004.2493]), 'iscrowd': tensor([0])}\n",
      "{'boxes': tensor([[136.6070, 188.9102, 232.3862, 234.3723]]), 'labels': tensor([1]), 'image_id': tensor([152]), 'extra': 'patient26677/study1/view1_frontal.jpg', 'area': tensor([4354.3223]), 'iscrowd': tensor([0])}\n",
      "{'boxes': tensor([[158.8999, 191.5586, 253.7964, 230.8414]]), 'labels': tensor([1]), 'image_id': tensor([199]), 'extra': 'patient34405/study1/view1_frontal.jpg', 'area': tensor([3727.8069]), 'iscrowd': tensor([0])}\n",
      "{'boxes': tensor([[169.0242, 171.6966, 276.7206, 229.0758]]), 'labels': tensor([1]), 'image_id': tensor([108]), 'extra': 'patient18734/study1/view1_frontal.jpg', 'area': tensor([6179.5337]), 'iscrowd': tensor([0])}\n",
      "{'boxes': tensor([[104.0138, 137.9172, 240.1104, 220.7585]]), 'labels': tensor([1]), 'image_id': tensor([76]), 'extra': 'patient13853/study5/view1_frontal.jpg', 'area': tensor([11274.4111]), 'iscrowd': tensor([0])}\n",
      "{'boxes': tensor([[130.4275, 200.8277, 226.2067, 256.4414]]), 'labels': tensor([1]), 'image_id': tensor([176]), 'extra': 'patient30750/study1/view1_frontal.jpg', 'area': tensor([5326.6411]), 'iscrowd': tensor([0])}\n",
      "{'boxes': tensor([[128.8669, 165.3412, 228.9974, 225.0831]]), 'labels': tensor([1]), 'image_id': tensor([22]), 'extra': 'patient04039/study1/view1_frontal.jpg', 'area': tensor([5981.9800]), 'iscrowd': tensor([0])}\n",
      "{'boxes': tensor([[ 99.2098, 152.2251, 262.0742, 242.6600]]), 'labels': tensor([1]), 'image_id': tensor([54]), 'extra': 'patient10713/study5/view1_frontal.jpg', 'area': tensor([14728.6221]), 'iscrowd': tensor([0])}\n",
      "{'boxes': tensor([[134.2400, 195.4205, 221.2909, 254.9351]]), 'labels': tensor([1]), 'image_id': tensor([172]), 'extra': 'patient30231/study4/view1_frontal.jpg', 'area': tensor([5180.7993]), 'iscrowd': tensor([0])}\n",
      "{'boxes': tensor([[107.3904, 166.3725, 213.0595, 223.9284]]), 'labels': tensor([1]), 'image_id': tensor([32]), 'extra': 'patient07399/study1/view1_frontal.jpg', 'area': tensor([6081.8872]), 'iscrowd': tensor([0])}\n",
      "{'boxes': tensor([[152.2791, 206.5654, 272.3344, 255.1171]]), 'labels': tensor([1]), 'image_id': tensor([83]), 'extra': 'patient14768/study1/view1_frontal.jpg', 'area': tensor([5828.8843]), 'iscrowd': tensor([0])}\n",
      "{'boxes': tensor([[114.0965, 189.7930, 261.9586, 263.0621]]), 'labels': tensor([1]), 'image_id': tensor([150]), 'extra': 'patient25308/study1/view1_frontal.jpg', 'area': tensor([10833.7236]), 'iscrowd': tensor([0])}\n",
      "{'boxes': tensor([[116.5274, 179.1998, 301.0241, 278.5103]]), 'labels': tensor([1]), 'image_id': tensor([187]), 'extra': 'patient31890/study12/view1_frontal.jpg', 'area': tensor([18322.4395]), 'iscrowd': tensor([0])}\n",
      "{'boxes': tensor([[150.0723, 172.5794, 261.3000, 224.6622]]), 'labels': tensor([1]), 'image_id': tensor([131]), 'extra': 'patient22482/study3/view1_frontal.jpg', 'area': tensor([5793.0576]), 'iscrowd': tensor([0])}\n",
      "{'boxes': tensor([[131.7648, 175.9592, 217.6982, 222.1995]]), 'labels': tensor([1]), 'image_id': tensor([17]), 'extra': 'patient02506/study2/view1_frontal.jpg', 'area': tensor([3973.5903]), 'iscrowd': tensor([0])}\n",
      "{'boxes': tensor([[128.6621, 176.9933, 264.6070, 244.5242]]), 'labels': tensor([1]), 'image_id': tensor([123]), 'extra': 'patient20617/study3/view1_frontal.jpg', 'area': tensor([9180.4805]), 'iscrowd': tensor([0])}\n",
      "{'boxes': tensor([[161.0138, 167.7243, 270.0345, 230.8414]]), 'labels': tensor([1]), 'image_id': tensor([38]), 'extra': 'patient08555/study1/view1_frontal.jpg', 'area': tensor([6881.0679]), 'iscrowd': tensor([0])}\n",
      "{'boxes': tensor([[135.5068, 152.7173, 287.3414, 244.5243]]), 'labels': tensor([1]), 'image_id': tensor([138]), 'extra': 'patient22949/study1/view1_frontal.jpg', 'area': tensor([13939.4883]), 'iscrowd': tensor([0])}\n",
      "{'boxes': tensor([[140.7672, 192.7365, 246.3426, 249.2072]]), 'labels': tensor([1]), 'image_id': tensor([6]), 'extra': 'patient00881/study1/view1_frontal.jpg', 'area': tensor([5961.9165]), 'iscrowd': tensor([0])}\n",
      "{'boxes': tensor([[122.2147, 168.1840, 259.2991, 245.5242]]), 'labels': tensor([1]), 'image_id': tensor([4]), 'extra': 'patient00987/study2/view1_frontal.jpg', 'area': tensor([10602.1328]), 'iscrowd': tensor([0])}\n",
      "{'boxes': tensor([[159.2483, 197.7379, 271.3585, 244.0829]]), 'labels': tensor([1]), 'image_id': tensor([193]), 'extra': 'patient32351/study1/view1_frontal.jpg', 'area': tensor([5195.7432]), 'iscrowd': tensor([0])}\n",
      "{'boxes': tensor([[111.0069, 154.0414, 225.7656, 226.4277]]), 'labels': tensor([1]), 'image_id': tensor([116]), 'extra': 'patient20162/study5/view1_frontal.jpg', 'area': tensor([8306.9502]), 'iscrowd': tensor([0])}\n",
      "{'boxes': tensor([[109.2413, 173.4621, 252.6896, 243.6413]]), 'labels': tensor([1]), 'image_id': tensor([191]), 'extra': 'patient32404/study1/view1_frontal.jpg', 'area': tensor([10067.0889]), 'iscrowd': tensor([0])}\n",
      "{'boxes': tensor([[131.8456, 202.4443, 241.3352, 265.9036]]), 'labels': tensor([1]), 'image_id': tensor([62]), 'extra': 'patient12188/study1/view1_frontal.jpg', 'area': tensor([6948.1328]), 'iscrowd': tensor([0])}\n",
      "{'boxes': tensor([[110.8950, 119.4885, 246.3427, 186.5986]]), 'labels': tensor([1]), 'image_id': tensor([49]), 'extra': 'patient09617/study3/view1_frontal.jpg', 'area': tensor([9089.9033]), 'iscrowd': tensor([0])}\n",
      "{'boxes': tensor([[100.2557, 166.5474, 261.4832, 242.2507]]), 'labels': tensor([1]), 'image_id': tensor([63]), 'extra': 'patient12233/study1/view1_frontal.jpg', 'area': tensor([12205.4629]), 'iscrowd': tensor([0])}\n",
      "{'boxes': tensor([[122.0413, 167.7242, 280.9379, 264.8275]]), 'labels': tensor([1]), 'image_id': tensor([164]), 'extra': 'patient26845/study1/view1_frontal.jpg', 'area': tensor([15429.3955]), 'iscrowd': tensor([0])}\n",
      "{'boxes': tensor([[113.6552, 159.3379, 234.5931, 232.1654]]), 'labels': tensor([1]), 'image_id': tensor([140]), 'extra': 'patient23710/study5/view1_frontal.jpg', 'area': tensor([8807.6084]), 'iscrowd': tensor([0])}\n",
      "{'boxes': tensor([[119.2137, 181.4069, 272.3723, 262.6206]]), 'labels': tensor([1]), 'image_id': tensor([86]), 'extra': 'patient15182/study1/view1_frontal.jpg', 'area': tensor([12438.5850]), 'iscrowd': tensor([0])}\n",
      "{'boxes': tensor([[118.7929, 144.7723, 280.3379, 245.4069]]), 'labels': tensor([1]), 'image_id': tensor([136]), 'extra': 'patient22730/study6/view1_frontal.jpg', 'area': tensor([16257.0039]), 'iscrowd': tensor([0])}\n",
      "{'boxes': tensor([[126.8965, 192.4413, 230.1794, 237.0205]]), 'labels': tensor([1]), 'image_id': tensor([86]), 'extra': 'patient15009/study11/view1_frontal.jpg', 'area': tensor([4604.2681]), 'iscrowd': tensor([0])}\n",
      "{'boxes': tensor([[143.8000, 202.1517, 267.3864, 271.0067]]), 'labels': tensor([1]), 'image_id': tensor([198]), 'extra': 'patient33677/study1/view1_frontal.jpg', 'area': tensor([8509.5400]), 'iscrowd': tensor([0])}\n",
      "{'boxes': tensor([[134.9726, 188.0275, 307.9933, 272.7725]]), 'labels': tensor([1]), 'image_id': tensor([89]), 'extra': 'patient15452/study2/view1_frontal.jpg', 'area': tensor([14662.6396]), 'iscrowd': tensor([0])}\n",
      "{'boxes': tensor([[ 84.9656, 149.1862, 263.2827, 267.0345]]), 'labels': tensor([1]), 'image_id': tensor([155]), 'extra': 'patient26120/study3/view1_frontal.jpg', 'area': tensor([21014.3711]), 'iscrowd': tensor([0])}\n",
      "{'boxes': tensor([[169.8413, 153.5998, 293.8687, 224.6619]]), 'labels': tensor([1]), 'image_id': tensor([154]), 'extra': 'patient26014/study1/view1_frontal.jpg', 'area': tensor([8813.6475]), 'iscrowd': tensor([0])}\n",
      "{'boxes': tensor([[142.2449, 154.9242, 276.8656, 226.4275]]), 'labels': tensor([1]), 'image_id': tensor([182]), 'extra': 'patient29775/study1/view1_frontal.jpg', 'area': tensor([9625.8311]), 'iscrowd': tensor([0])}\n",
      "{'boxes': tensor([[135.2482, 190.6758, 260.1585, 254.6758]]), 'labels': tensor([1]), 'image_id': tensor([40]), 'extra': 'patient08771/study1/view1_frontal.jpg', 'area': tensor([7994.2637]), 'iscrowd': tensor([0])}\n",
      "{'boxes': tensor([[107.0346, 176.1102, 264.6070, 253.7931]]), 'labels': tensor([1]), 'image_id': tensor([119]), 'extra': 'patient20253/study8/view1_frontal.jpg', 'area': tensor([12240.6826]), 'iscrowd': tensor([0])}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'boxes': tensor([[ 96.0000, 183.6138, 244.3034, 270.5654]]), 'labels': tensor([1]), 'image_id': tensor([132]), 'extra': 'patient21789/study3/view1_frontal.jpg', 'area': tensor([12895.2256]), 'iscrowd': tensor([0])}\n",
      "{'boxes': tensor([[114.7955, 170.6395, 311.6242, 254.9362]]), 'labels': tensor([1]), 'image_id': tensor([22]), 'extra': 'patient04499/study1/view1_frontal.jpg', 'area': tensor([16591.9961]), 'iscrowd': tensor([0])}\n",
      "{'boxes': tensor([[145.3019, 169.9447, 252.7806, 215.8757]]), 'labels': tensor([1]), 'image_id': tensor([140]), 'extra': 'patient23864/study2/view1_frontal.jpg', 'area': tensor([4936.6079]), 'iscrowd': tensor([0])}\n",
      "{'boxes': tensor([[157.5757, 224.6619, 272.7757, 272.7723]]), 'labels': tensor([1]), 'image_id': tensor([142]), 'extra': 'patient24320/study2/view1_frontal.jpg', 'area': tensor([5542.3145]), 'iscrowd': tensor([0])}\n",
      "{'boxes': tensor([[142.3450, 170.3723, 249.6000, 223.7794]]), 'labels': tensor([1]), 'image_id': tensor([187]), 'extra': 'patient31912/study1/view1_frontal.jpg', 'area': tensor([5728.1753]), 'iscrowd': tensor([0])}\n",
      "{'boxes': tensor([[138.7477, 181.5311, 229.0706, 229.7919]]), 'labels': tensor([1]), 'image_id': tensor([173]), 'extra': 'patient30268/study1/view1_frontal.jpg', 'area': tensor([4359.0503]), 'iscrowd': tensor([0])}\n",
      "{'boxes': tensor([[171.6070, 174.3446, 312.4072, 220.6896]]), 'labels': tensor([1]), 'image_id': tensor([157]), 'extra': 'patient27667/study1/view1_frontal.jpg', 'area': tensor([6525.3784]), 'iscrowd': tensor([0])}\n",
      "{'boxes': tensor([[136.0654, 202.5930, 272.8931, 269.2413]]), 'labels': tensor([1]), 'image_id': tensor([151]), 'extra': 'patient25828/study4/view1_frontal.jpg', 'area': tensor([9119.3398]), 'iscrowd': tensor([0])}\n",
      "{'boxes': tensor([[131.7517, 181.8482, 232.8275, 236.1378]]), 'labels': tensor([1]), 'image_id': tensor([54]), 'extra': 'patient10738/study3/view1_frontal.jpg', 'area': tensor([5487.3662]), 'iscrowd': tensor([0])}\n",
      "{'boxes': tensor([[115.4206, 194.2069, 222.2344, 246.2898]]), 'labels': tensor([1]), 'image_id': tensor([138]), 'extra': 'patient23581/study2/view1_frontal.jpg', 'area': tensor([5563.1694]), 'iscrowd': tensor([0])}\n",
      "{'boxes': tensor([[141.9035, 192.4413, 234.5931, 239.6688]]), 'labels': tensor([1]), 'image_id': tensor([71]), 'extra': 'patient13529/study1/view1_frontal.jpg', 'area': tensor([4377.4990]), 'iscrowd': tensor([0])}\n",
      "{'boxes': tensor([[135.5069, 185.8205, 238.7897, 232.1654]]), 'labels': tensor([1]), 'image_id': tensor([167]), 'extra': 'patient29392/study4/view1_frontal.jpg', 'area': tensor([4786.6333]), 'iscrowd': tensor([0])}\n",
      "{'boxes': tensor([[ 95.1171, 152.2758, 255.3379, 236.5792]]), 'labels': tensor([1]), 'image_id': tensor([98]), 'extra': 'patient16341/study1/view1_frontal.jpg', 'area': tensor([13507.1514]), 'iscrowd': tensor([0])}\n",
      "{'boxes': tensor([[121.5344, 175.1408, 224.2454, 250.4349]]), 'labels': tensor([1]), 'image_id': tensor([10]), 'extra': 'patient01544/study1/view1_frontal.jpg', 'area': tensor([7733.5332]), 'iscrowd': tensor([0])}\n",
      "{'boxes': tensor([[110.3482, 135.5035, 273.2170, 284.6898]]), 'labels': tensor([1]), 'image_id': tensor([85]), 'extra': 'patient15113/study3/view1_frontal.jpg', 'area': tensor([24297.7910]), 'iscrowd': tensor([0])}\n",
      "{'boxes': tensor([[145.2174, 194.6483, 269.6862, 265.2691]]), 'labels': tensor([1]), 'image_id': tensor([44]), 'extra': 'patient09340/study3/view1_frontal.jpg', 'area': tensor([8790.0928]), 'iscrowd': tensor([0])}\n",
      "{'boxes': tensor([[137.0331, 190.6904, 261.4322, 265.1662]]), 'labels': tensor([1]), 'image_id': tensor([20]), 'extra': 'patient04098/study4/view1_frontal.jpg', 'area': tensor([9264.7256]), 'iscrowd': tensor([0])}\n",
      "{'boxes': tensor([[136.7661, 152.2251, 254.6177, 234.4757]]), 'labels': tensor([1]), 'image_id': tensor([7]), 'extra': 'patient02130/study1/view1_frontal.jpg', 'area': tensor([9693.3613]), 'iscrowd': tensor([0])}\n",
      "{'boxes': tensor([[109.3875, 217.6981, 306.6252, 298.7211]]), 'labels': tensor([1]), 'image_id': tensor([23]), 'extra': 'patient04837/study1/view1_frontal.jpg', 'area': tensor([15980.7998]), 'iscrowd': tensor([0])}\n",
      "{'boxes': tensor([[138.5966, 215.3930, 270.5691, 265.2688]]), 'labels': tensor([1]), 'image_id': tensor([120]), 'extra': 'patient20500/study2/view1_frontal.jpg', 'area': tensor([6582.2378]), 'iscrowd': tensor([0])}\n",
      "{'boxes': tensor([[112.3309, 164.1930, 246.9517, 239.6688]]), 'labels': tensor([1]), 'image_id': tensor([64]), 'extra': 'patient12663/study3/view1_frontal.jpg', 'area': tensor([10160.6162]), 'iscrowd': tensor([0])}\n",
      "{'boxes': tensor([[163.6623, 190.6758, 262.0898, 232.6067]]), 'labels': tensor([1]), 'image_id': tensor([197]), 'extra': 'patient33346/study5/view1_frontal.jpg', 'area': tensor([4127.1484]), 'iscrowd': tensor([0])}\n",
      "{'boxes': tensor([[146.3174, 156.6896, 227.9725, 216.7171]]), 'labels': tensor([1]), 'image_id': tensor([139]), 'extra': 'patient23611/study1/view1_frontal.jpg', 'area': tensor([4901.5483]), 'iscrowd': tensor([0])}\n",
      "{'boxes': tensor([[107.7047, 167.7749, 256.2471, 234.8850]]), 'labels': tensor([1]), 'image_id': tensor([18]), 'extra': 'patient03665/study3/view1_frontal.jpg', 'area': tensor([9968.6914]), 'iscrowd': tensor([0])}\n",
      "{'boxes': tensor([[158.3654, 168.6067, 268.2689, 223.7792]]), 'labels': tensor([1]), 'image_id': tensor([42]), 'extra': 'patient09150/study2/view1_frontal.jpg', 'area': tensor([6063.6528]), 'iscrowd': tensor([0])}\n",
      "{'boxes': tensor([[132.1931, 163.7517, 261.9586, 249.3792]]), 'labels': tensor([1]), 'image_id': tensor([137]), 'extra': 'patient22829/study3/view1_frontal.jpg', 'area': tensor([11111.4922]), 'iscrowd': tensor([0])}\n",
      "{'boxes': tensor([[126.7967, 178.3173, 277.3069, 244.0827]]), 'labels': tensor([1]), 'image_id': tensor([98]), 'extra': 'patient16821/study1/view1_frontal.jpg', 'area': tensor([9898.3730]), 'iscrowd': tensor([0])}\n",
      "{'boxes': tensor([[128.4912, 164.0922, 223.8365, 224.6547]]), 'labels': tensor([1]), 'image_id': tensor([23]), 'extra': 'patient04097/study1/view1_frontal.jpg', 'area': tensor([5774.3550]), 'iscrowd': tensor([0])}\n",
      "{'boxes': tensor([[116.2149, 163.2734, 240.6139, 214.4245]]), 'labels': tensor([1]), 'image_id': tensor([5]), 'extra': 'patient00876/study1/view1_frontal.jpg', 'area': tensor([6363.1411]), 'iscrowd': tensor([0])}\n",
      "{'boxes': tensor([[140.4886, 146.9053, 285.3480, 226.2915]]), 'labels': tensor([1]), 'image_id': tensor([56]), 'extra': 'patient10864/study9/view1_frontal.jpg', 'area': tensor([11499.8418]), 'iscrowd': tensor([0])}\n",
      "{'boxes': tensor([[168.5172, 174.3450, 296.9587, 244.5242]]), 'labels': tensor([1]), 'image_id': tensor([63]), 'extra': 'patient12397/study1/view1_frontal.jpg', 'area': tensor([9013.9170]), 'iscrowd': tensor([0])}\n",
      "{'boxes': tensor([[174.2551, 198.1794, 282.8342, 261.7381]]), 'labels': tensor([1]), 'image_id': tensor([194]), 'extra': 'patient32524/study1/view1_frontal.jpg', 'area': tensor([6901.1465]), 'iscrowd': tensor([0])}\n",
      "{'boxes': tensor([[143.3518, 198.8747, 330.3596, 277.8517]]), 'labels': tensor([1]), 'image_id': tensor([60]), 'extra': 'patient11553/study1/view1_frontal.jpg', 'area': tensor([14769.3037]), 'iscrowd': tensor([0])}\n",
      "{'boxes': tensor([[116.5276, 180.9656, 263.0656, 273.6552]]), 'labels': tensor([1]), 'image_id': tensor([77]), 'extra': 'patient14064/study1/view1_frontal.jpg', 'area': tensor([13582.5518]), 'iscrowd': tensor([0])}\n",
      "{'boxes': tensor([[108.1415, 148.7448, 300.1414, 252.9102]]), 'labels': tensor([1]), 'image_id': tensor([124]), 'extra': 'patient21082/study5/view1_frontal.jpg', 'area': tensor([19999.7539]), 'iscrowd': tensor([0])}\n",
      "{'boxes': tensor([[ 95.6035, 168.0997, 271.6483, 284.7658]]), 'labels': tensor([1]), 'image_id': tensor([61]), 'extra': 'patient11989/study2/view1_frontal.jpg', 'area': tensor([20538.4590]), 'iscrowd': tensor([0])}\n",
      "{'boxes': tensor([[134.5767, 210.3325, 319.5383, 285.6266]]), 'labels': tensor([1]), 'image_id': tensor([16]), 'extra': 'patient03595/study1/view1_frontal.jpg', 'area': tensor([13926.5156]), 'iscrowd': tensor([0])}\n",
      "{'boxes': tensor([[143.1700, 157.1357, 276.1624, 213.1971]]), 'labels': tensor([1]), 'image_id': tensor([8]), 'extra': 'patient01134/study1/view1_frontal.jpg', 'area': tensor([7455.7437]), 'iscrowd': tensor([0])}\n",
      "{'boxes': tensor([[147.6414, 179.2000, 223.5586, 226.8691]]), 'labels': tensor([1]), 'image_id': tensor([81]), 'extra': 'patient14709/study1/view1_frontal.jpg', 'area': tensor([3618.9033]), 'iscrowd': tensor([0])}\n",
      "{'boxes': tensor([[121.8241, 146.0965, 289.1069, 238.7861]]), 'labels': tensor([1]), 'image_id': tensor([181]), 'extra': 'patient29763/study12/view1_frontal.jpg', 'area': tensor([15505.3770]), 'iscrowd': tensor([0])}\n",
      "{'boxes': tensor([[123.5318, 162.4552, 279.8490, 242.6597]]), 'labels': tensor([1]), 'image_id': tensor([53]), 'extra': 'patient10287/study1/view1_frontal.jpg', 'area': tensor([12537.3447]), 'iscrowd': tensor([0])}\n",
      "{'boxes': tensor([[163.6621, 154.0413, 267.8276, 211.4205]]), 'labels': tensor([1]), 'image_id': tensor([112]), 'extra': 'patient19503/study1/view1_frontal.jpg', 'area': tensor([5976.9341]), 'iscrowd': tensor([0])}\n",
      "{'boxes': tensor([[129.7758, 189.7931, 234.3827, 227.3102]]), 'labels': tensor([1]), 'image_id': tensor([122]), 'extra': 'patient21071/study2/view1_frontal.jpg', 'area': tensor([3924.5503]), 'iscrowd': tensor([0])}\n",
      "{'boxes': tensor([[137.0689, 177.8760, 255.3585, 223.3381]]), 'labels': tensor([1]), 'image_id': tensor([55]), 'extra': 'patient10739/study1/view1_frontal.jpg', 'area': tensor([5377.6914]), 'iscrowd': tensor([0])}\n",
      "{'boxes': tensor([[141.4621, 173.0208, 227.0896, 222.8966]]), 'labels': tensor([1]), 'image_id': tensor([84]), 'extra': 'patient14817/study1/view1_frontal.jpg', 'area': tensor([4270.7441]), 'iscrowd': tensor([0])}\n",
      "{'boxes': tensor([[165.5758, 210.0966, 281.6587, 263.9449]]), 'labels': tensor([1]), 'image_id': tensor([191]), 'extra': 'patient32209/study3/view2_frontal.jpg', 'area': tensor([6250.8682]), 'iscrowd': tensor([0])}\n",
      "{'boxes': tensor([[166.3104, 180.0827, 285.4827, 232.1656]]), 'labels': tensor([1]), 'image_id': tensor([67]), 'extra': 'patient13081/study1/view1_frontal.jpg', 'area': tensor([6206.8374]), 'iscrowd': tensor([0])}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'boxes': tensor([[144.0358, 189.0536, 261.8875, 236.1125]]), 'labels': tensor([1]), 'image_id': tensor([7]), 'extra': 'patient01094/study11/view1_frontal.jpg', 'area': tensor([5545.9663]), 'iscrowd': tensor([0])}\n",
      "{'boxes': tensor([[110.7006, 179.8758, 234.6152, 221.6247]]), 'labels': tensor([1]), 'image_id': tensor([179]), 'extra': 'patient31010/study3/view1_frontal.jpg', 'area': tensor([5173.2988]), 'iscrowd': tensor([0])}\n",
      "{'boxes': tensor([[110.9397, 168.5933, 261.9373, 263.9386]]), 'labels': tensor([1]), 'image_id': tensor([5]), 'extra': 'patient01167/study48/view1_frontal.jpg', 'area': tensor([14396.9092]), 'iscrowd': tensor([0])}\n",
      "{'boxes': tensor([[176.0206, 182.2896, 277.9791, 232.1654]]), 'labels': tensor([1]), 'image_id': tensor([184]), 'extra': 'patient31459/study1/view1_frontal.jpg', 'area': tensor([5085.2646]), 'iscrowd': tensor([0])}\n",
      "{'boxes': tensor([[102.6208, 171.6963, 234.5933, 244.9654]]), 'labels': tensor([1]), 'image_id': tensor([133]), 'extra': 'patient21850/study1/view1_frontal.jpg', 'area': tensor([9669.5068]), 'iscrowd': tensor([0])}\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from PIL import Image\n",
    "import torchvision\n",
    "from torchvision.models.detection.faster_rcnn import FastRCNNPredictor\n",
    "\n",
    "from datasets.heartdatasets import VinBigDataHeartDataset\n",
    "\n",
    "import torchvision.transforms as T\n",
    "from models.fastrcnn import get_model\n",
    "\n",
    "def get_transform(train):\n",
    "    transforms = []\n",
    "    transforms.append(T.ToTensor())\n",
    "    return T.Compose(transforms)\n",
    "\n",
    "def get_vinbigdata_dataframe(path):\n",
    "    IMG_SIZE = 512\n",
    "    df = pd.read_csv(path)\n",
    "    df['x_min'] = IMG_SIZE * df['x_min'] / df['width']\n",
    "    df['x_max'] = IMG_SIZE * df['x_max'] / df['width']\n",
    "    df['y_min'] = IMG_SIZE * df['y_min'] / df['height']\n",
    "    df['y_max'] = IMG_SIZE * df['y_max'] / df['height']\n",
    "    df = df[df.class_name.eq('Cardiomegaly')]\n",
    "    return df\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "df = get_vinbigdata_dataframe('./data/vinbigdata/train.csv')\n",
    "df_train, df_test = train_test_split(df, test_size=0.33, random_state=42)\n",
    "\n",
    "#TODO: Check bug with data augmentation\n",
    "ds_train = VinBigDataHeartDataset(df, './data/vinbigdata/train/', get_transform(train=False))\n",
    "ds_test = VinBigDataHeartDataset(df, './data/vinbigdata/train/', get_transform(train=False))\n",
    "\n",
    "from datasets.heartdatasets import CheXpertHeartDataset\n",
    "import torch\n",
    "\n",
    "ds_train_no_finding = CheXpertHeartDataset('./data/hand-label/nofinding/','../CheXpert-v1.0-small/train' ,get_transform(train=False), test= True)\n",
    "ds_train_cardiomegaly = CheXpertHeartDataset('./data/hand-label/cardiomegaly-certain/','../CheXpert-v1.0-small/train' ,get_transform(train=False), test= True)\n",
    "\n",
    "full_ds_chexpert2 = torch.utils.data.ConcatDataset([ds_train_no_finding, ds_train_cardiomegaly])\n",
    "\n",
    "train_ds_chexpert2,val_ds_chexpert2 = torch.utils.data.random_split(full_ds_chexpert2, [len(full_ds_chexpert2) - 100, 100], generator=torch.Generator().manual_seed(42))\n",
    "\n",
    "len(ds_train_no_finding), len(ds_train_cardiomegaly), len(full_ds_chexpert2)\n",
    "\n",
    "print(len(val_ds_chexpert2))\n",
    "\n",
    "ground_truth_heart = {}\n",
    "for idx in range(len(val_ds_chexpert1)):\n",
    "    image, data = val_ds_chexpert2[idx]\n",
    "    if 'boxes' in data:\n",
    "        ground_truth_heart[data['extra']] =  data['boxes'][0].cpu().numpy()\n",
    "        #x0,y0,x1,y1\n",
    "    print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0e59c0de",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch.utils.data.dataset.Subset at 0x1b1b785e310>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_ds_chexpert1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b64b8625",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████| 9547/9547 [00:14<00:00, 651.13it/s]\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import torch\n",
    "import os\n",
    "import cv2\n",
    "import torch\n",
    "import torchvision.transforms as T\n",
    "from PIL import Image\n",
    "from models.fastrcnn import get_model\n",
    "\n",
    "def get_transform(train):\n",
    "    transforms = []\n",
    "    transforms.append(T.ToTensor())\n",
    "    return T.Compose(transforms)\n",
    "\n",
    "def evaluate_image(model, path,device):\n",
    "    img_loaded = cv2.imread(path, cv2.IMREAD_COLOR)\n",
    "    img_loaded = get_transform(train=False)(img_loaded)\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        prediction = model([img_loaded.to(device)])\n",
    "        return img_loaded,prediction[0]\n",
    "\n",
    "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
    "\n",
    "# our dataset has two classes only - background and person\n",
    "num_classes = 2\n",
    "\n",
    "# get the model using our helper function\n",
    "model = get_model(num_classes)\n",
    "# move model to the right device\n",
    "model.to(device)\n",
    "\n",
    "name = 'modelPRETRAINING9'\n",
    "model_params = torch.load(f'./intermediate/heart_weights/{name}.pth')\n",
    "model.load_state_dict(model_params)\n",
    "\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "import pickle\n",
    "\n",
    "CHEXPERT_VALIDATION_BASE = './data/chexpert-cardio-nofinding'\n",
    "\n",
    "paths = os.listdir(CHEXPERT_VALIDATION_BASE)\n",
    "\n",
    "predictions_heart = {}\n",
    "for p in tqdm(paths):\n",
    "    if p.replace('_','/',2) in ground_truth_heart:\n",
    "        prediction = evaluate_image(model, CHEXPERT_VALIDATION_BASE+'/'+p,device)\n",
    "        if len(prediction[1]['boxes']) > 0:\n",
    "            predictions_heart[p.replace('_','/',2)] = ((prediction[1]['boxes'])[0],prediction[0].shape)\n",
    "    #predictions.append(prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9ed16517",
   "metadata": {},
   "outputs": [],
   "source": [
    "#ground_truth_heart"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cf84ffca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100\n",
      "100\n"
     ]
    }
   ],
   "source": [
    "print(len(ground_truth_lungs))\n",
    "print(len(ground_truth_heart))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "45fcea77",
   "metadata": {},
   "outputs": [],
   "source": [
    "#for i in range(99):\n",
    "#    print(val_ds_chexpert1[i][2],val_ds_chexpert2[i][1]['extra'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fc743b8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#val_ds_chexpert1[1],val_ds_chexpert2[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "62735a15",
   "metadata": {},
   "outputs": [],
   "source": [
    "#for k in zip(predictions_heart,predictions_lungs):\n",
    "#    print(k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "8eb209cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "count = 0\n",
    "errors = []\n",
    "errors_heart = []\n",
    "errors_lung = []\n",
    "h = []\n",
    "l = []\n",
    "r = []\n",
    "ious = []\n",
    "for x in list(ground_truth_heart):\n",
    "    a = ground_truth_lungs[x.replace('/','_',2)]\n",
    "    b = ground_truth_heart[x] \n",
    "    c = predictions_lungs[x.replace('/','_',2)]\n",
    "    d = predictions_heart[x]\n",
    "    count +=1\n",
    "    \n",
    "    start_lung, finish_lung, width_true = a\n",
    "    start_heart,y0,finish_heart,y1 = b\n",
    "    \n",
    "    start_lung_pred, finish_lung_pred, width_pred = c\n",
    "    box, width_heart = d\n",
    "    (start_heart_pred,y0_pred,finish_heart_pred,y1_pred)= box.cpu().numpy()\n",
    "    \n",
    "    true_lung_ratio = (finish_lung-start_lung)/width_true\n",
    "    true_heart_ratio = (finish_heart-start_heart)/width_heart[2]\n",
    "    true_ctr = true_heart_ratio / true_lung_ratio   \n",
    "    \n",
    "    h.append(true_heart_ratio)\n",
    "    l.append(true_lung_ratio)\n",
    "    r.append(true_ctr)\n",
    "\n",
    "    \n",
    "    \n",
    "    pred_lung_ratio = (finish_lung_pred-start_lung_pred)/width_pred\n",
    "    pred_heart_ratio = (finish_heart_pred-start_heart_pred)/width_heart[2]\n",
    "    \n",
    "    pred_ctr = pred_heart_ratio / pred_lung_ratio\n",
    "    \n",
    "    iou = get_iou([start_heart_pred,y0_pred,finish_heart_pred,y1_pred], [start_heart,y0,finish_heart,y1], epsilon=1e-5)\n",
    "    ious.append(iou)\n",
    "    errors.append(abs(true_ctr - pred_ctr))\n",
    "    errors_lung.append(abs(true_lung_ratio - pred_lung_ratio))\n",
    "    errors_heart.append(abs(true_heart_ratio - pred_heart_ratio))\n",
    "\n",
    "\n",
    "errors = np.array(errors)\n",
    "errors_heart = np.array(errors_heart)\n",
    "errors_lung = np.array(errors_lung)\n",
    "ious = np.array(ious)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "72ca112a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.36982068849439054, 0.7808437500000003, 0.4814576276285776)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(h).mean(), np.array(l).mean(), np.array(r).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "53cd35b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "94\n",
      "20\n",
      "0\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "print(np.sum(ious > 0.5))\n",
    "print(np.sum(ious > 0.75))\n",
    "print(np.sum(ious > 0.90))\n",
    "print(np.sum(ious > 0.95))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e88f4d0b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3f022812",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "71"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(errors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0d01080c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 0.05804989810656875\n",
      "Min: 0.00013080488847294625\n",
      "Max: 0.09817309713914624\n",
      "Mean: 0.04993748811442437\n",
      "Median: 0.05373089601964132\n",
      "STD: 0.029597938289765015\n"
     ]
    }
   ],
   "source": [
    "print('RMSE:', np.sqrt((errors ** 2).sum()/len(errors)))\n",
    "print('Min:', errors.min())\n",
    "print('Max:', errors.max())\n",
    "print('Mean:', errors.mean())\n",
    "print('Median:', np.median(errors))\n",
    "print('STD:', errors.std())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "82bb04d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 0.04188291734850444\n",
      "Min: 0.00024076806245787452\n",
      "Max: 0.07994424291403895\n",
      "Mean: 0.0355311624799446\n",
      "Median: 0.036852818838557844\n",
      "STD: 0.022174653513537274\n"
     ]
    }
   ],
   "source": [
    "print('RMSE:', np.sqrt((errors_heart ** 2).sum()/len(errors_heart)))\n",
    "print('Min:', errors_heart.min())\n",
    "print('Max:', errors_heart.max())\n",
    "print('Mean:', errors_heart.mean())\n",
    "print('Median:', np.median(errors_heart))\n",
    "print('STD:', errors_heart.std())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "423a99e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 0.02625013754365374\n",
      "Min: 0.0007812499999999556\n",
      "Max: 0.10507812500000002\n",
      "Mean: 0.01923415492957746\n",
      "Median: 0.016015624999999978\n",
      "STD: 0.017863846316114297\n"
     ]
    }
   ],
   "source": [
    "print('RMSE:', np.sqrt((errors_lung ** 2).sum()/len(errors_lung)))\n",
    "print('Min:', errors_lung.min())\n",
    "print('Max:', errors_lung.max())\n",
    "print('Mean:', errors_lung.mean())\n",
    "print('Median:', np.median(errors_lung))\n",
    "print('STD:', errors_lung.std())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "38a4ab10",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 0.6646610622989084\n",
      "Min: 0.0\n",
      "Max: 0.8932249262245379\n",
      "Mean: 0.6513585370877115\n",
      "Median: 0.6609620090586962\n",
      "STD: 0.13231169222434508\n"
     ]
    }
   ],
   "source": [
    "print('RMSE:', np.sqrt((ious ** 2).sum()/len(ious)))\n",
    "print('Min:', ious.min())\n",
    "print('Max:', ious.max())\n",
    "print('Mean:', ious.mean())\n",
    "print('Median:', np.median(ious))\n",
    "print('STD:', ious.std())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cs230-project",
   "language": "python",
   "name": "cs230-project"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
