{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3fe7ebd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_iou(a, b, epsilon=1e-5):\n",
    "    \"\"\" Given two boxes `a` and `b` defined as a list of four numbers:\n",
    "            [x1,y1,x2,y2]\n",
    "        where:\n",
    "            x1,y1 represent the upper left corner\n",
    "            x2,y2 represent the lower right corner\n",
    "        It returns the Intersect of Union score for these two boxes.\n",
    "\n",
    "    Args:\n",
    "        a:          (list of 4 numbers) [x1,y1,x2,y2]\n",
    "        b:          (list of 4 numbers) [x1,y1,x2,y2]\n",
    "        epsilon:    (float) Small value to prevent division by zero\n",
    "\n",
    "    Returns:\n",
    "        (float) The Intersect of Union score.\n",
    "    \"\"\"\n",
    "    # COORDINATES OF THE INTERSECTION BOX\n",
    "    x1 = max(a[0], b[0])\n",
    "    y1 = max(a[1], b[1])\n",
    "    x2 = min(a[2], b[2])\n",
    "    y2 = min(a[3], b[3])\n",
    "\n",
    "    # AREA OF OVERLAP - Area where the boxes intersect\n",
    "    width = (x2 - x1)\n",
    "    height = (y2 - y1)\n",
    "    # handle case where there is NO overlap\n",
    "    if (width<0) or (height <0):\n",
    "        return 0.0\n",
    "    area_overlap = width * height\n",
    "\n",
    "    # COMBINED AREA\n",
    "    area_a = (a[2] - a[0]) * (a[3] - a[1])\n",
    "    area_b = (b[2] - b[0]) * (b[3] - b[1])\n",
    "    area_combined = area_a + area_b - area_overlap\n",
    "\n",
    "    # RATIO OF AREA OF OVERLAP OVER COMBINED AREA\n",
    "    iou = area_overlap / (area_combined+epsilon)\n",
    "    return iou"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e92ad7bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "import albumentations as A\n",
    "\n",
    "from datasets.lungdatasets import SchenzenMontgomeryLungSegmentationDataset\n",
    "from datasets.lungdatasets import CheXpertLungSegmentationDataset\n",
    "from models.unet import ResNetUNet\n",
    "from utils.utils import bce_dice_loss, dice_metric\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import glob\n",
    "import cv2\n",
    "\n",
    "CHEXPERT_TRAIN = '../CheXpert-v1.0-small/train.csv'\n",
    "BASE_MASKS = './intermediate/out_lung_mask/'\n",
    "BASE_IMG = './data/chexpert-cardio-nofinding/'\n",
    "BASE_EXTRA = 'CheXpert-v1.0-small/train/'\n",
    "\n",
    "def get_transforms(size, test = True):\n",
    "    #Do test-time augmentation?\n",
    "    if test:\n",
    "        return A.Compose([\n",
    "        A.Resize(height=size, width=size, p=1.0)\n",
    "        ])\n",
    "    return A.Compose([\n",
    "        A.Resize(height=size, width=size, p=1.0),\n",
    "        A.HorizontalFlip(p=0.5),\n",
    "        A.RandomRotate90(p=0.3),\n",
    "        A.Transpose(p=0.3),\n",
    "        A.ShiftScaleRotate(shift_limit=0.05, scale_limit=0.2, rotate_limit=45, p=0.3),\n",
    "    ])\n",
    "\n",
    "#Find Min skipping 0\n",
    "def find_min(arr):\n",
    "    min_val = 1000\n",
    "    for idx, value in enumerate(arr):\n",
    "        if value < min_val and value != 0:\n",
    "            min_val = value\n",
    "    return min_val\n",
    "\n",
    "def find_chest_width_image(img,post_process=True):\n",
    "    if post_process:\n",
    "        img = post_process_image(img)\n",
    "    start = np.argmax(img[:,:,1],axis=1)\n",
    "    end = np.argmax(img[:,::-1,1],axis=1)\n",
    "    h,w,c = img.shape\n",
    "    return find_min(start), w - find_min(end), w\n",
    "\n",
    "def find_chest_width(path,post_process=True):\n",
    "    img = cv2.imread(path)\n",
    "    if post_process:\n",
    "        img = post_process_image(img)\n",
    "    start = np.argmax(img[:,:,1],axis=1)\n",
    "    end = np.argmax(img[:,::-1,1],axis=1)\n",
    "    h,w,c = img.shape\n",
    "    return find_min(start), w - find_min(end), w\n",
    "\n",
    "def post_process_image(img,hull = True):\n",
    "    \n",
    "    dst = img[:,:,0]\n",
    "    \n",
    "    #kernel = np.ones((3, 3), np.uint8)\n",
    "    #dst = cv2.erode(dst, kernel,iterations= 3) \n",
    "\n",
    "    contours, hierarchy = cv2.findContours(dst, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "    #create an empty image for contours\n",
    "    img_contours = np.zeros(img.shape)\n",
    "    # draw the contours on the empty image\n",
    "    cs = [(c,cv2.contourArea(c)) for c in contours]\n",
    "    cs.sort(key=lambda x:x[1])\n",
    "    if hull:\n",
    "        hulls = [cv2.convexHull(p[0]) for p in cs[-2:]]\n",
    "        cv2.drawContours(img_contours, hulls, -1, (0,255,0), -1)\n",
    "    else:\n",
    "        contours2 = [p[0] for p in cs[-2:]]\n",
    "        cv2.drawContours(img_contours, contours2, -1, (0,255,0), -1)\n",
    "    return img_contours\n",
    "\n",
    "def find_img(path):\n",
    "    img = cv2.imread(path)\n",
    "    return img.shape\n",
    "\n",
    "import numpy as np\n",
    "import cv2\n",
    "from matplotlib.pyplot import imshow\n",
    "\n",
    "ds_train_no_finding = CheXpertLungSegmentationDataset(\"./data/hand-label/nofinding.json\", '../CheXpert-v1.0-small/train/'\n",
    "                                                      , aug_transform=get_transforms(320)\n",
    "                                                     , test = True)\n",
    "ds_train_cardiomegaly = CheXpertLungSegmentationDataset(\"./data/hand-label/cardiomegaly-certain.json\", '../CheXpert-v1.0-small/train/'\n",
    "                                                        , aug_transform=get_transforms(320)\n",
    "                                                       , test = True)\n",
    "\n",
    "full_ds_chexpert1 = torch.utils.data.ConcatDataset([ds_train_no_finding, ds_train_cardiomegaly])\n",
    "train_ds_chexpert1,val_ds_chexpert1 = torch.utils.data.random_split(full_ds_chexpert1, [len(full_ds_chexpert1) - 100, 100], generator=torch.Generator().manual_seed(42))\n",
    "sample = np.uint8(full_ds_chexpert1[0][1].cpu().numpy() * 255)\n",
    "\n",
    "ground_truth_lungs = {}\n",
    "for img,mask,path in val_ds_chexpert1:\n",
    "    print(path)\n",
    "    mask = np.uint8(mask *255)\n",
    "    ground_truth_lungs[path] = find_chest_width_image((np.stack([mask,mask,mask])*255).transpose(1,2,0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95be3fc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import torch\n",
    "from tqdm import tqdm\n",
    "import cv2\n",
    "import albumentations as A\n",
    "import numpy as np\n",
    "from datasets.lungdatasets import MEAN,STD\n",
    "from models.unet import ResNetUNet\n",
    "\n",
    "# \n",
    "IMAGE_SIZE = 512\n",
    "\n",
    "LUNG_MODEL_WEIGHTS = './intermediate/lung_mask_weights'\n",
    "PATH = \"./intermediate/out_lung_mask3/\"\n",
    "\n",
    "\n",
    "base_path = 'C:/Users/ignacio/workspace/stanford/cs230/CheXpert-v1.0-small/train/'\n",
    "CHEXPERT_VALIDATION_BASE = './data/chexpert-cardio-nofinding'\n",
    "\n",
    "paths = os.listdir(CHEXPERT_VALIDATION_BASE)\n",
    "inference_transforms = A.Compose([A.Resize(height=IMAGE_SIZE, width=IMAGE_SIZE, p=1.0)])\n",
    "\n",
    "def load_image(base_path, path):\n",
    "    path = path.replace('_','/',2)\n",
    "    img_path = base_path + path\n",
    "    image = cv2.imread(img_path,0)\n",
    "    image = cv2.merge([image,image,image])\n",
    "    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "    augmented = inference_transforms(image=image)\n",
    "    image = augmented['image']\n",
    "    image = A.Normalize(mean=MEAN, std=STD)(image=image)[\"image\"]\n",
    "    return torch.FloatTensor(image).unsqueeze(0)\n",
    "\n",
    "model = ResNetUNet().cuda()\n",
    "\n",
    "#best_weights = sorted(glob.glob(LUNG_MODEL_WEIGHTS + \"/*\"), key=lambda x: x[8:-5])[-1]\n",
    "\n",
    "#checkpoint = torch.load('./intermediate/lung_mask_weights/pretraining0.903464_.pth')\n",
    "checkpoint = torch.load('./intermediate/lung_mask_weights/afterpretraining0.941366_.pth')\n",
    "#checkpoint = torch.load('./intermediate/lung_mask_weights/nopretraining0.914747_.pth')\n",
    "model.load_state_dict(checkpoint['state_dict'])\n",
    "\n",
    "model.eval()\n",
    "predictions_lungs = {}\n",
    "\n",
    "for p in tqdm(paths): \n",
    "    if p in ground_truth_lungs:\n",
    "        img = load_image(base_path, p)\n",
    "        data_batch = img.permute(0, 3, 1, 2).cuda()\n",
    "        outputs = model(data_batch)\n",
    "\n",
    "        out_cut = np.copy(outputs.data.cpu().numpy())\n",
    "        out_cut[np.nonzero(out_cut < 0.5)] = 0.0\n",
    "        out_cut[np.nonzero(out_cut >= 0.5)] = 1.0\n",
    "\n",
    "        mask = ((out_cut[0].transpose(1, 2, 0) * 255).astype(np.uint8))[:,:,0]\n",
    "        prediction = find_chest_width_image((np.stack([mask,mask,mask]).transpose(1,2,0)))\n",
    "        predictions_lungs[p] = prediction\n",
    "        #cv2.imwrite(PATH + p, (out_cut[0].transpose(1, 2, 0) * 255).astype(np.uint8))\n",
    "    \n",
    "    #print(np.stack([mask,mask,mask]).shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21fb8d35",
   "metadata": {},
   "source": [
    "# Heart"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "565ff4d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from PIL import Image\n",
    "import torchvision\n",
    "from torchvision.models.detection.faster_rcnn import FastRCNNPredictor\n",
    "\n",
    "from datasets.heartdatasets import VinBigDataHeartDataset\n",
    "\n",
    "import torchvision.transforms as T\n",
    "from models.fastrcnn import get_model\n",
    "\n",
    "def get_transform(train):\n",
    "    transforms = []\n",
    "    transforms.append(T.ToTensor())\n",
    "    return T.Compose(transforms)\n",
    "\n",
    "def get_vinbigdata_dataframe(path):\n",
    "    IMG_SIZE = 512\n",
    "    df = pd.read_csv(path)\n",
    "    df['x_min'] = IMG_SIZE * df['x_min'] / df['width']\n",
    "    df['x_max'] = IMG_SIZE * df['x_max'] / df['width']\n",
    "    df['y_min'] = IMG_SIZE * df['y_min'] / df['height']\n",
    "    df['y_max'] = IMG_SIZE * df['y_max'] / df['height']\n",
    "    df = df[df.class_name.eq('Cardiomegaly')]\n",
    "    return df\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "df = get_vinbigdata_dataframe('./data/vinbigdata/train.csv')\n",
    "df_train, df_test = train_test_split(df, test_size=0.33, random_state=42)\n",
    "\n",
    "\n",
    "ds_train = VinBigDataHeartDataset(df, './data/vinbigdata/train/', get_transform(train=False))\n",
    "ds_test = VinBigDataHeartDataset(df, './data/vinbigdata/train/', get_transform(train=False))\n",
    "\n",
    "from datasets.heartdatasets import CheXpertHeartDataset\n",
    "import torch\n",
    "\n",
    "ds_train_no_finding = CheXpertHeartDataset('./data/hand-label/nofinding/','../CheXpert-v1.0-small/train' ,get_transform(train=False), test= True)\n",
    "ds_train_cardiomegaly = CheXpertHeartDataset('./data/hand-label/cardiomegaly-certain/','../CheXpert-v1.0-small/train' ,get_transform(train=False), test= True)\n",
    "\n",
    "full_ds_chexpert2 = torch.utils.data.ConcatDataset([ds_train_no_finding, ds_train_cardiomegaly])\n",
    "\n",
    "train_ds_chexpert2,val_ds_chexpert2 = torch.utils.data.random_split(full_ds_chexpert2, [len(full_ds_chexpert2) - 100, 100], generator=torch.Generator().manual_seed(42))\n",
    "\n",
    "len(ds_train_no_finding), len(ds_train_cardiomegaly), len(full_ds_chexpert2)\n",
    "\n",
    "print(len(val_ds_chexpert2))\n",
    "\n",
    "ground_truth_heart = {}\n",
    "for idx in range(len(val_ds_chexpert1)):\n",
    "    image, data = val_ds_chexpert2[idx]\n",
    "    if 'boxes' in data:\n",
    "        ground_truth_heart[data['extra']] =  data['boxes'][0].cpu().numpy()\n",
    "        #x0,y0,x1,y1\n",
    "    print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e59c0de",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds_chexpert1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b64b8625",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import torch\n",
    "import os\n",
    "import cv2\n",
    "import torch\n",
    "import torchvision.transforms as T\n",
    "from PIL import Image\n",
    "from models.fastrcnn import get_model\n",
    "\n",
    "def get_transform(train):\n",
    "    transforms = []\n",
    "    transforms.append(T.ToTensor())\n",
    "    return T.Compose(transforms)\n",
    "\n",
    "def evaluate_image(model, path,device):\n",
    "    img_loaded = cv2.imread(path, cv2.IMREAD_COLOR)\n",
    "    img_loaded = get_transform(train=False)(img_loaded)\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        prediction = model([img_loaded.to(device)])\n",
    "        return img_loaded,prediction[0]\n",
    "\n",
    "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
    "\n",
    "# our dataset has two classes only - background and person\n",
    "num_classes = 2\n",
    "\n",
    "# get the model using our helper function\n",
    "model = get_model(num_classes)\n",
    "# move model to the right device\n",
    "model.to(device)\n",
    "\n",
    "name = 'modelPRETRAINING9'\n",
    "model_params = torch.load(f'./intermediate/heart_weights/{name}.pth')\n",
    "model.load_state_dict(model_params)\n",
    "\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "import pickle\n",
    "\n",
    "CHEXPERT_VALIDATION_BASE = './data/chexpert-cardio-nofinding'\n",
    "\n",
    "paths = os.listdir(CHEXPERT_VALIDATION_BASE)\n",
    "\n",
    "predictions_heart = {}\n",
    "for p in tqdm(paths):\n",
    "    if p.replace('_','/',2) in ground_truth_heart:\n",
    "        prediction = evaluate_image(model, CHEXPERT_VALIDATION_BASE+'/'+p,device)\n",
    "        if len(prediction[1]['boxes']) > 0:\n",
    "            predictions_heart[p.replace('_','/',2)] = ((prediction[1]['boxes'])[0],prediction[0].shape)\n",
    "    #predictions.append(prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ed16517",
   "metadata": {},
   "outputs": [],
   "source": [
    "#ground_truth_heart"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf84ffca",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(ground_truth_lungs))\n",
    "print(len(ground_truth_heart))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45fcea77",
   "metadata": {},
   "outputs": [],
   "source": [
    "#for i in range(99):\n",
    "#    print(val_ds_chexpert1[i][2],val_ds_chexpert2[i][1]['extra'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc743b8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#val_ds_chexpert1[1],val_ds_chexpert2[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62735a15",
   "metadata": {},
   "outputs": [],
   "source": [
    "#for k in zip(predictions_heart,predictions_lungs):\n",
    "#    print(k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8eb209cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "count = 0\n",
    "errors = []\n",
    "errors_heart = []\n",
    "errors_lung = []\n",
    "h = []\n",
    "l = []\n",
    "r = []\n",
    "ious = []\n",
    "for x in list(ground_truth_heart):\n",
    "    a = ground_truth_lungs[x.replace('/','_',2)]\n",
    "    b = ground_truth_heart[x] \n",
    "    c = predictions_lungs[x.replace('/','_',2)]\n",
    "    d = predictions_heart[x]\n",
    "    count +=1\n",
    "    \n",
    "    start_lung, finish_lung, width_true = a\n",
    "    start_heart,y0,finish_heart,y1 = b\n",
    "    \n",
    "    start_lung_pred, finish_lung_pred, width_pred = c\n",
    "    box, width_heart = d\n",
    "    (start_heart_pred,y0_pred,finish_heart_pred,y1_pred)= box.cpu().numpy()\n",
    "    \n",
    "    true_lung_ratio = (finish_lung-start_lung)/width_true\n",
    "    true_heart_ratio = (finish_heart-start_heart)/width_heart[2]\n",
    "    true_ctr = true_heart_ratio / true_lung_ratio   \n",
    "    \n",
    "    h.append(true_heart_ratio)\n",
    "    l.append(true_lung_ratio)\n",
    "    r.append(true_ctr)\n",
    "\n",
    "    \n",
    "    \n",
    "    pred_lung_ratio = (finish_lung_pred-start_lung_pred)/width_pred\n",
    "    pred_heart_ratio = (finish_heart_pred-start_heart_pred)/width_heart[2]\n",
    "    \n",
    "    pred_ctr = pred_heart_ratio / pred_lung_ratio\n",
    "    \n",
    "    iou = get_iou([start_heart_pred,y0_pred,finish_heart_pred,y1_pred], [start_heart,y0,finish_heart,y1], epsilon=1e-5)\n",
    "    ious.append(iou)\n",
    "    errors.append(abs(true_ctr - pred_ctr))\n",
    "    errors_lung.append(abs(true_lung_ratio - pred_lung_ratio))\n",
    "    errors_heart.append(abs(true_heart_ratio - pred_heart_ratio))\n",
    "\n",
    "\n",
    "errors = np.array(errors)\n",
    "errors_heart = np.array(errors_heart)\n",
    "errors_lung = np.array(errors_lung)\n",
    "ious = np.array(ious)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72ca112a",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.array(h).mean(), np.array(l).mean(), np.array(r).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53cd35b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(np.sum(ious > 0.5))\n",
    "print(np.sum(ious > 0.75))\n",
    "print(np.sum(ious > 0.90))\n",
    "print(np.sum(ious > 0.95))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e88f4d0b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f022812",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(errors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d01080c",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('RMSE:', np.sqrt((errors ** 2).sum()/len(errors)))\n",
    "print('Min:', errors.min())\n",
    "print('Max:', errors.max())\n",
    "print('Mean:', errors.mean())\n",
    "print('Median:', np.median(errors))\n",
    "print('STD:', errors.std())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82bb04d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('RMSE:', np.sqrt((errors_heart ** 2).sum()/len(errors_heart)))\n",
    "print('Min:', errors_heart.min())\n",
    "print('Max:', errors_heart.max())\n",
    "print('Mean:', errors_heart.mean())\n",
    "print('Median:', np.median(errors_heart))\n",
    "print('STD:', errors_heart.std())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "423a99e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('RMSE:', np.sqrt((errors_lung ** 2).sum()/len(errors_lung)))\n",
    "print('Min:', errors_lung.min())\n",
    "print('Max:', errors_lung.max())\n",
    "print('Mean:', errors_lung.mean())\n",
    "print('Median:', np.median(errors_lung))\n",
    "print('STD:', errors_lung.std())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38a4ab10",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('RMSE:', np.sqrt((ious ** 2).sum()/len(ious)))\n",
    "print('Min:', ious.min())\n",
    "print('Max:', ious.max())\n",
    "print('Mean:', ious.mean())\n",
    "print('Median:', np.median(ious))\n",
    "print('STD:', ious.std())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cs230-project",
   "language": "python",
   "name": "cs230-project"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
